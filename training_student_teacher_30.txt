nohup: ignoring input
2024-05-02 21:25:59.918711: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-05-02 21:25:59.918775: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-05-02 21:25:59.919995: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-05-02 21:25:59.926349: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-02 21:26:00.753176: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-05-02 21:26:01.615203: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-05-02 21:26:01.653864: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-05-02 21:26:01.654169: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-05-02 21:26:01.924454: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-05-02 21:26:01.924813: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-05-02 21:26:01.925144: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-05-02 21:26:02.019122: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-05-02 21:26:02.019544: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-05-02 21:26:02.019884: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-05-02 21:26:02.020124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3352 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1
Num GPUs Available:  1
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 112, 112, 3)]     0         
                                                                 
 conv2d (Conv2D)             (None, 55, 55, 24)        672       
                                                                 
 batch_normalization (Batch  (None, 55, 55, 24)        96        
 Normalization)                                                  
                                                                 
 activation (Activation)     (None, 55, 55, 24)        0         
                                                                 
 linear_bottleneck_block (L  (None, 28, 28, 24)        1368      
 inearBottleneckBlock)                                           
                                                                 
 linear_bottleneck_block_1   (None, 28, 28, 24)        1368      
 (LinearBottleneckBlock)                                         
                                                                 
 linear_bottleneck_block_2   (None, 28, 28, 24)        1368      
 (LinearBottleneckBlock)                                         
                                                                 
 linear_bottleneck_block_3   (None, 28, 28, 24)        1368      
 (LinearBottleneckBlock)                                         
                                                                 
 linear_bottleneck_block_4   (None, 14, 14, 96)        4464      
 (LinearBottleneckBlock)                                         
                                                                 
 linear_bottleneck_block_5   (None, 14, 14, 96)        12384     
 (LinearBottleneckBlock)                                         
                                                                 
 linear_bottleneck_block_6   (None, 14, 14, 96)        12384     
 (LinearBottleneckBlock)                                         
                                                                 
 linear_bottleneck_block_7   (None, 14, 14, 96)        12384     
 (LinearBottleneckBlock)                                         
                                                                 
 linear_bottleneck_block_8   (None, 7, 7, 168)         20664     
 (LinearBottleneckBlock)                                         
                                                                 
 linear_bottleneck_block_9   (None, 7, 7, 168)         33768     
 (LinearBottleneckBlock)                                         
                                                                 
 linear_bottleneck_block_10  (None, 7, 7, 168)         33768     
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_11  (None, 4, 4, 192)         38256     
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_12  (None, 4, 4, 384)         83712     
  (LinearBottleneckBlock)                                        
                                                                 
 global_average_pooling2d (  (None, 384)               0         
 GlobalAveragePooling2D)                                         
                                                                 
 dropout (Dropout)           (None, 384)               0         
                                                                 
 output_1 (Dense)            (None, 200)               77000     
                                                                 
 output_2 (TempatureSoftmax  (None, 200)               0         
 ActivationLayer)                                                
                                                                 
=================================================================
Total params: 335024 (1.28 MB)
Trainable params: 326336 (1.24 MB)
Non-trainable params: 8688 (33.94 KB)
_________________________________________________________________
Epoch 1/100
2024-05-02 21:30:12.817251: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
2024-05-02 21:30:14.636049: I external/local_xla/xla/service/service.cc:168] XLA service 0x560bcacd0b10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2024-05-02 21:30:14.636690: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1060 6GB, Compute Capability 6.1
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1714681814.700302  865946 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
782/782 - 98s - loss: 6.3566 - output_1_loss: 4.5192 - output_2_loss: 0.0612 - output_1_Top-1 Accuracy: 0.0990 - output_1_Top-5 Accuracy: 0.2550 - val_loss: 5.3284 - val_output_1_loss: 3.7094 - val_output_2_loss: 0.0540 - val_output_1_Top-1 Accuracy: 0.1867 - val_output_1_Top-5 Accuracy: 0.4241 - lr: 0.1000 - 98s/epoch - 126ms/step
Epoch 2/100
782/782 - 90s - loss: 5.3885 - output_1_loss: 3.5508 - output_2_loss: 0.0613 - output_1_Top-1 Accuracy: 0.2062 - output_1_Top-5 Accuracy: 0.4654 - val_loss: 5.1007 - val_output_1_loss: 3.5148 - val_output_2_loss: 0.0529 - val_output_1_Top-1 Accuracy: 0.2130 - val_output_1_Top-5 Accuracy: 0.4732 - lr: 0.1000 - 90s/epoch - 115ms/step
Epoch 3/100
782/782 - 111s - loss: 5.0907 - output_1_loss: 3.3189 - output_2_loss: 0.0591 - output_1_Top-1 Accuracy: 0.2349 - output_1_Top-5 Accuracy: 0.5245 - val_loss: 4.8496 - val_output_1_loss: 3.3342 - val_output_2_loss: 0.0505 - val_output_1_Top-1 Accuracy: 0.2311 - val_output_1_Top-5 Accuracy: 0.5198 - lr: 0.1000 - 111s/epoch - 142ms/step
Epoch 4/100
782/782 - 114s - loss: 4.8995 - output_1_loss: 3.1974 - output_2_loss: 0.0567 - output_1_Top-1 Accuracy: 0.2486 - output_1_Top-5 Accuracy: 0.5559 - val_loss: 4.8064 - val_output_1_loss: 3.3464 - val_output_2_loss: 0.0487 - val_output_1_Top-1 Accuracy: 0.2260 - val_output_1_Top-5 Accuracy: 0.5223 - lr: 0.1000 - 114s/epoch - 146ms/step
Epoch 5/100
782/782 - 114s - loss: 4.7677 - output_1_loss: 3.1125 - output_2_loss: 0.0552 - output_1_Top-1 Accuracy: 0.2593 - output_1_Top-5 Accuracy: 0.5792 - val_loss: 4.9678 - val_output_1_loss: 3.5010 - val_output_2_loss: 0.0489 - val_output_1_Top-1 Accuracy: 0.1971 - val_output_1_Top-5 Accuracy: 0.4889 - lr: 0.1000 - 114s/epoch - 146ms/step
Epoch 6/100
782/782 - 113s - loss: 4.6681 - output_1_loss: 3.0486 - output_2_loss: 0.0540 - output_1_Top-1 Accuracy: 0.2657 - output_1_Top-5 Accuracy: 0.5953 - val_loss: 4.7056 - val_output_1_loss: 3.2571 - val_output_2_loss: 0.0483 - val_output_1_Top-1 Accuracy: 0.2427 - val_output_1_Top-5 Accuracy: 0.5415 - lr: 0.1000 - 113s/epoch - 145ms/step
Epoch 7/100
782/782 - 113s - loss: 4.5795 - output_1_loss: 2.9887 - output_2_loss: 0.0530 - output_1_Top-1 Accuracy: 0.2722 - output_1_Top-5 Accuracy: 0.6082 - val_loss: 4.8903 - val_output_1_loss: 3.4383 - val_output_2_loss: 0.0484 - val_output_1_Top-1 Accuracy: 0.2020 - val_output_1_Top-5 Accuracy: 0.4983 - lr: 0.1000 - 113s/epoch - 145ms/step
Epoch 8/100
782/782 - 113s - loss: 4.4982 - output_1_loss: 2.9366 - output_2_loss: 0.0521 - output_1_Top-1 Accuracy: 0.2767 - output_1_Top-5 Accuracy: 0.6202 - val_loss: 4.6316 - val_output_1_loss: 3.2666 - val_output_2_loss: 0.0455 - val_output_1_Top-1 Accuracy: 0.2335 - val_output_1_Top-5 Accuracy: 0.5568 - lr: 0.1000 - 113s/epoch - 145ms/step
Epoch 9/100
782/782 - 115s - loss: 4.4401 - output_1_loss: 2.8969 - output_2_loss: 0.0514 - output_1_Top-1 Accuracy: 0.2841 - output_1_Top-5 Accuracy: 0.6274 - val_loss: 4.4405 - val_output_1_loss: 3.1059 - val_output_2_loss: 0.0445 - val_output_1_Top-1 Accuracy: 0.2490 - val_output_1_Top-5 Accuracy: 0.5881 - lr: 0.1000 - 115s/epoch - 147ms/step
Epoch 10/100
782/782 - 113s - loss: 4.3813 - output_1_loss: 2.8562 - output_2_loss: 0.0508 - output_1_Top-1 Accuracy: 0.2883 - output_1_Top-5 Accuracy: 0.6383 - val_loss: 4.6404 - val_output_1_loss: 3.2925 - val_output_2_loss: 0.0449 - val_output_1_Top-1 Accuracy: 0.2247 - val_output_1_Top-5 Accuracy: 0.5478 - lr: 0.1000 - 113s/epoch - 144ms/step
Epoch 11/100
782/782 - 113s - loss: 4.3365 - output_1_loss: 2.8275 - output_2_loss: 0.0503 - output_1_Top-1 Accuracy: 0.2938 - output_1_Top-5 Accuracy: 0.6455 - val_loss: 5.1891 - val_output_1_loss: 3.7312 - val_output_2_loss: 0.0486 - val_output_1_Top-1 Accuracy: 0.1697 - val_output_1_Top-5 Accuracy: 0.4719 - lr: 0.1000 - 113s/epoch - 144ms/step
Epoch 12/100

Epoch 12: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.
782/782 - 113s - loss: 4.2955 - output_1_loss: 2.7995 - output_2_loss: 0.0499 - output_1_Top-1 Accuracy: 0.2955 - output_1_Top-5 Accuracy: 0.6524 - val_loss: 4.4424 - val_output_1_loss: 3.1253 - val_output_2_loss: 0.0439 - val_output_1_Top-1 Accuracy: 0.2511 - val_output_1_Top-5 Accuracy: 0.5805 - lr: 0.1000 - 113s/epoch - 144ms/step
Epoch 13/100
782/782 - 113s - loss: 4.0599 - output_1_loss: 2.6139 - output_2_loss: 0.0482 - output_1_Top-1 Accuracy: 0.3278 - output_1_Top-5 Accuracy: 0.6911 - val_loss: 4.0057 - val_output_1_loss: 2.7711 - val_output_2_loss: 0.0412 - val_output_1_Top-1 Accuracy: 0.3036 - val_output_1_Top-5 Accuracy: 0.6636 - lr: 0.0100 - 113s/epoch - 145ms/step
Epoch 14/100
782/782 - 113s - loss: 3.9834 - output_1_loss: 2.5529 - output_2_loss: 0.0477 - output_1_Top-1 Accuracy: 0.3364 - output_1_Top-5 Accuracy: 0.7028 - val_loss: 3.9943 - val_output_1_loss: 2.7642 - val_output_2_loss: 0.0410 - val_output_1_Top-1 Accuracy: 0.3043 - val_output_1_Top-5 Accuracy: 0.6617 - lr: 0.0100 - 113s/epoch - 145ms/step
Epoch 15/100
782/782 - 115s - loss: 3.9528 - output_1_loss: 2.5308 - output_2_loss: 0.0474 - output_1_Top-1 Accuracy: 0.3376 - output_1_Top-5 Accuracy: 0.7089 - val_loss: 3.9795 - val_output_1_loss: 2.7530 - val_output_2_loss: 0.0409 - val_output_1_Top-1 Accuracy: 0.3081 - val_output_1_Top-5 Accuracy: 0.6625 - lr: 0.0100 - 115s/epoch - 147ms/step
Epoch 16/100
782/782 - 117s - loss: 3.9269 - output_1_loss: 2.5134 - output_2_loss: 0.0471 - output_1_Top-1 Accuracy: 0.3408 - output_1_Top-5 Accuracy: 0.7124 - val_loss: 3.9772 - val_output_1_loss: 2.7546 - val_output_2_loss: 0.0408 - val_output_1_Top-1 Accuracy: 0.3064 - val_output_1_Top-5 Accuracy: 0.6628 - lr: 0.0100 - 117s/epoch - 150ms/step
Epoch 17/100
782/782 - 114s - loss: 3.9103 - output_1_loss: 2.5002 - output_2_loss: 0.0470 - output_1_Top-1 Accuracy: 0.3414 - output_1_Top-5 Accuracy: 0.7150 - val_loss: 3.9779 - val_output_1_loss: 2.7569 - val_output_2_loss: 0.0407 - val_output_1_Top-1 Accuracy: 0.3055 - val_output_1_Top-5 Accuracy: 0.6619 - lr: 0.0100 - 114s/epoch - 146ms/step
Epoch 18/100
782/782 - 118s - loss: 3.8903 - output_1_loss: 2.4873 - output_2_loss: 0.0468 - output_1_Top-1 Accuracy: 0.3433 - output_1_Top-5 Accuracy: 0.7189 - val_loss: 3.9752 - val_output_1_loss: 2.7558 - val_output_2_loss: 0.0406 - val_output_1_Top-1 Accuracy: 0.3047 - val_output_1_Top-5 Accuracy: 0.6628 - lr: 0.0100 - 118s/epoch - 150ms/step
Epoch 19/100
782/782 - 114s - loss: 3.8785 - output_1_loss: 2.4785 - output_2_loss: 0.0467 - output_1_Top-1 Accuracy: 0.3452 - output_1_Top-5 Accuracy: 0.7204 - val_loss: 3.9839 - val_output_1_loss: 2.7683 - val_output_2_loss: 0.0405 - val_output_1_Top-1 Accuracy: 0.3006 - val_output_1_Top-5 Accuracy: 0.6589 - lr: 0.0100 - 114s/epoch - 145ms/step
Epoch 20/100
782/782 - 115s - loss: 3.8642 - output_1_loss: 2.4681 - output_2_loss: 0.0465 - output_1_Top-1 Accuracy: 0.3465 - output_1_Top-5 Accuracy: 0.7223 - val_loss: 3.9757 - val_output_1_loss: 2.7623 - val_output_2_loss: 0.0404 - val_output_1_Top-1 Accuracy: 0.2999 - val_output_1_Top-5 Accuracy: 0.6613 - lr: 0.0100 - 115s/epoch - 148ms/step
Epoch 21/100

Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.
782/782 - 108s - loss: 3.8536 - output_1_loss: 2.4620 - output_2_loss: 0.0464 - output_1_Top-1 Accuracy: 0.3466 - output_1_Top-5 Accuracy: 0.7238 - val_loss: 3.9812 - val_output_1_loss: 2.7685 - val_output_2_loss: 0.0404 - val_output_1_Top-1 Accuracy: 0.2990 - val_output_1_Top-5 Accuracy: 0.6641 - lr: 0.0100 - 108s/epoch - 138ms/step
Epoch 22/100
782/782 - 74s - loss: 3.8201 - output_1_loss: 2.4337 - output_2_loss: 0.0462 - output_1_Top-1 Accuracy: 0.3523 - output_1_Top-5 Accuracy: 0.7290 - val_loss: 3.9637 - val_output_1_loss: 2.7576 - val_output_2_loss: 0.0402 - val_output_1_Top-1 Accuracy: 0.3003 - val_output_1_Top-5 Accuracy: 0.6631 - lr: 1.0000e-03 - 74s/epoch - 94ms/step
Epoch 23/100
782/782 - 75s - loss: 3.8104 - output_1_loss: 2.4273 - output_2_loss: 0.0461 - output_1_Top-1 Accuracy: 0.3536 - output_1_Top-5 Accuracy: 0.7306 - val_loss: 3.9625 - val_output_1_loss: 2.7576 - val_output_2_loss: 0.0402 - val_output_1_Top-1 Accuracy: 0.3010 - val_output_1_Top-5 Accuracy: 0.6624 - lr: 1.0000e-03 - 75s/epoch - 96ms/step
Epoch 24/100
782/782 - 74s - loss: 3.8099 - output_1_loss: 2.4262 - output_2_loss: 0.0461 - output_1_Top-1 Accuracy: 0.3524 - output_1_Top-5 Accuracy: 0.7315 - val_loss: 3.9639 - val_output_1_loss: 2.7604 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.2993 - val_output_1_Top-5 Accuracy: 0.6637 - lr: 1.0000e-03 - 74s/epoch - 94ms/step
Epoch 25/100
782/782 - 74s - loss: 3.8051 - output_1_loss: 2.4228 - output_2_loss: 0.0461 - output_1_Top-1 Accuracy: 0.3548 - output_1_Top-5 Accuracy: 0.7320 - val_loss: 3.9648 - val_output_1_loss: 2.7614 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.3017 - val_output_1_Top-5 Accuracy: 0.6631 - lr: 1.0000e-03 - 74s/epoch - 94ms/step
Epoch 26/100

Epoch 26: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.
782/782 - 74s - loss: 3.8031 - output_1_loss: 2.4209 - output_2_loss: 0.0461 - output_1_Top-1 Accuracy: 0.3551 - output_1_Top-5 Accuracy: 0.7328 - val_loss: 3.9627 - val_output_1_loss: 2.7605 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.3014 - val_output_1_Top-5 Accuracy: 0.6622 - lr: 1.0000e-03 - 74s/epoch - 94ms/step
Epoch 27/100
782/782 - 94s - loss: 3.7999 - output_1_loss: 2.4186 - output_2_loss: 0.0460 - output_1_Top-1 Accuracy: 0.3547 - output_1_Top-5 Accuracy: 0.7332 - val_loss: 3.9613 - val_output_1_loss: 2.7572 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.3014 - val_output_1_Top-5 Accuracy: 0.6640 - lr: 1.0000e-04 - 94s/epoch - 120ms/step
Epoch 28/100
782/782 - 100s - loss: 3.7936 - output_1_loss: 2.4122 - output_2_loss: 0.0460 - output_1_Top-1 Accuracy: 0.3567 - output_1_Top-5 Accuracy: 0.7334 - val_loss: 3.9625 - val_output_1_loss: 2.7586 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.3003 - val_output_1_Top-5 Accuracy: 0.6643 - lr: 1.0000e-04 - 100s/epoch - 128ms/step
Epoch 29/100
782/782 - 79s - loss: 3.7993 - output_1_loss: 2.4181 - output_2_loss: 0.0460 - output_1_Top-1 Accuracy: 0.3540 - output_1_Top-5 Accuracy: 0.7343 - val_loss: 3.9618 - val_output_1_loss: 2.7584 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.3000 - val_output_1_Top-5 Accuracy: 0.6637 - lr: 1.0000e-04 - 79s/epoch - 101ms/step
Epoch 30/100

Epoch 30: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.
782/782 - 95s - loss: 3.7971 - output_1_loss: 2.4169 - output_2_loss: 0.0460 - output_1_Top-1 Accuracy: 0.3553 - output_1_Top-5 Accuracy: 0.7344 - val_loss: 3.9653 - val_output_1_loss: 2.7627 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.3002 - val_output_1_Top-5 Accuracy: 0.6635 - lr: 1.0000e-04 - 95s/epoch - 122ms/step
Epoch 31/100
782/782 - 86s - loss: 3.7950 - output_1_loss: 2.4159 - output_2_loss: 0.0460 - output_1_Top-1 Accuracy: 0.3563 - output_1_Top-5 Accuracy: 0.7338 - val_loss: 3.9617 - val_output_1_loss: 2.7581 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.3013 - val_output_1_Top-5 Accuracy: 0.6641 - lr: 1.0000e-05 - 86s/epoch - 110ms/step
Epoch 32/100
782/782 - 103s - loss: 3.7987 - output_1_loss: 2.4185 - output_2_loss: 0.0460 - output_1_Top-1 Accuracy: 0.3558 - output_1_Top-5 Accuracy: 0.7320 - val_loss: 3.9627 - val_output_1_loss: 2.7596 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.3008 - val_output_1_Top-5 Accuracy: 0.6635 - lr: 1.0000e-05 - 103s/epoch - 132ms/step
Epoch 33/100

Epoch 33: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.
782/782 - 101s - loss: 3.7977 - output_1_loss: 2.4161 - output_2_loss: 0.0461 - output_1_Top-1 Accuracy: 0.3547 - output_1_Top-5 Accuracy: 0.7340 - val_loss: 3.9634 - val_output_1_loss: 2.7602 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.3013 - val_output_1_Top-5 Accuracy: 0.6631 - lr: 1.0000e-05 - 101s/epoch - 129ms/step
Epoch 34/100
782/782 - 101s - loss: 3.7992 - output_1_loss: 2.4176 - output_2_loss: 0.0461 - output_1_Top-1 Accuracy: 0.3537 - output_1_Top-5 Accuracy: 0.7321 - val_loss: 3.9631 - val_output_1_loss: 2.7600 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.2987 - val_output_1_Top-5 Accuracy: 0.6628 - lr: 1.0000e-06 - 101s/epoch - 129ms/step
Epoch 35/100
782/782 - 101s - loss: 3.7912 - output_1_loss: 2.4124 - output_2_loss: 0.0460 - output_1_Top-1 Accuracy: 0.3545 - output_1_Top-5 Accuracy: 0.7342 - val_loss: 3.9611 - val_output_1_loss: 2.7576 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.2998 - val_output_1_Top-5 Accuracy: 0.6629 - lr: 1.0000e-06 - 101s/epoch - 129ms/step
Epoch 36/100
782/782 - 101s - loss: 3.7955 - output_1_loss: 2.4159 - output_2_loss: 0.0460 - output_1_Top-1 Accuracy: 0.3550 - output_1_Top-5 Accuracy: 0.7338 - val_loss: 3.9631 - val_output_1_loss: 2.7597 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.3011 - val_output_1_Top-5 Accuracy: 0.6634 - lr: 1.0000e-06 - 101s/epoch - 129ms/step
Epoch 37/100
782/782 - 101s - loss: 3.7999 - output_1_loss: 2.4187 - output_2_loss: 0.0460 - output_1_Top-1 Accuracy: 0.3544 - output_1_Top-5 Accuracy: 0.7338 - val_loss: 3.9635 - val_output_1_loss: 2.7597 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.2999 - val_output_1_Top-5 Accuracy: 0.6635 - lr: 1.0000e-06 - 101s/epoch - 129ms/step
Epoch 38/100

Epoch 38: ReduceLROnPlateau reducing learning rate to 1e-07.
782/782 - 101s - loss: 3.7989 - output_1_loss: 2.4176 - output_2_loss: 0.0460 - output_1_Top-1 Accuracy: 0.3546 - output_1_Top-5 Accuracy: 0.7329 - val_loss: 3.9642 - val_output_1_loss: 2.7613 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.3001 - val_output_1_Top-5 Accuracy: 0.6641 - lr: 1.0000e-06 - 101s/epoch - 129ms/step
Epoch 39/100
782/782 - 101s - loss: 3.7946 - output_1_loss: 2.4125 - output_2_loss: 0.0461 - output_1_Top-1 Accuracy: 0.3554 - output_1_Top-5 Accuracy: 0.7337 - val_loss: 3.9608 - val_output_1_loss: 2.7577 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.3002 - val_output_1_Top-5 Accuracy: 0.6643 - lr: 1.0000e-07 - 101s/epoch - 130ms/step
Epoch 40/100
782/782 - 101s - loss: 3.7963 - output_1_loss: 2.4164 - output_2_loss: 0.0460 - output_1_Top-1 Accuracy: 0.3554 - output_1_Top-5 Accuracy: 0.7335 - val_loss: 3.9622 - val_output_1_loss: 2.7583 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.3001 - val_output_1_Top-5 Accuracy: 0.6644 - lr: 1.0000e-07 - 101s/epoch - 129ms/step
Epoch 41/100
782/782 - 101s - loss: 3.8022 - output_1_loss: 2.4205 - output_2_loss: 0.0461 - output_1_Top-1 Accuracy: 0.3538 - output_1_Top-5 Accuracy: 0.7329 - val_loss: 3.9635 - val_output_1_loss: 2.7604 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.2999 - val_output_1_Top-5 Accuracy: 0.6629 - lr: 1.0000e-07 - 101s/epoch - 129ms/step
Epoch 42/100
782/782 - 104s - loss: 3.7973 - output_1_loss: 2.4153 - output_2_loss: 0.0461 - output_1_Top-1 Accuracy: 0.3537 - output_1_Top-5 Accuracy: 0.7332 - val_loss: 3.9611 - val_output_1_loss: 2.7571 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.3009 - val_output_1_Top-5 Accuracy: 0.6638 - lr: 1.0000e-07 - 104s/epoch - 133ms/step
Epoch 43/100
782/782 - 101s - loss: 3.8001 - output_1_loss: 2.4194 - output_2_loss: 0.0460 - output_1_Top-1 Accuracy: 0.3549 - output_1_Top-5 Accuracy: 0.7317 - val_loss: 3.9642 - val_output_1_loss: 2.7616 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.3001 - val_output_1_Top-5 Accuracy: 0.6638 - lr: 1.0000e-07 - 101s/epoch - 129ms/step
Epoch 44/100
782/782 - 104s - loss: 3.7980 - output_1_loss: 2.4161 - output_2_loss: 0.0461 - output_1_Top-1 Accuracy: 0.3542 - output_1_Top-5 Accuracy: 0.7330 - val_loss: 3.9633 - val_output_1_loss: 2.7592 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.3002 - val_output_1_Top-5 Accuracy: 0.6630 - lr: 1.0000e-07 - 104s/epoch - 133ms/step
Epoch 45/100
782/782 - 104s - loss: 3.7980 - output_1_loss: 2.4166 - output_2_loss: 0.0460 - output_1_Top-1 Accuracy: 0.3538 - output_1_Top-5 Accuracy: 0.7332 - val_loss: 3.9632 - val_output_1_loss: 2.7599 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.3003 - val_output_1_Top-5 Accuracy: 0.6624 - lr: 1.0000e-07 - 104s/epoch - 133ms/step
Epoch 46/100
782/782 - 101s - loss: 3.7928 - output_1_loss: 2.4127 - output_2_loss: 0.0460 - output_1_Top-1 Accuracy: 0.3553 - output_1_Top-5 Accuracy: 0.7341 - val_loss: 3.9621 - val_output_1_loss: 2.7594 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.2999 - val_output_1_Top-5 Accuracy: 0.6633 - lr: 1.0000e-07 - 101s/epoch - 129ms/step
Epoch 47/100
782/782 - 102s - loss: 3.7944 - output_1_loss: 2.4130 - output_2_loss: 0.0460 - output_1_Top-1 Accuracy: 0.3558 - output_1_Top-5 Accuracy: 0.7340 - val_loss: 3.9629 - val_output_1_loss: 2.7608 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.3000 - val_output_1_Top-5 Accuracy: 0.6629 - lr: 1.0000e-07 - 102s/epoch - 130ms/step
Epoch 48/100
782/782 - 101s - loss: 3.7966 - output_1_loss: 2.4150 - output_2_loss: 0.0461 - output_1_Top-1 Accuracy: 0.3562 - output_1_Top-5 Accuracy: 0.7339 - val_loss: 3.9611 - val_output_1_loss: 2.7573 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.3011 - val_output_1_Top-5 Accuracy: 0.6640 - lr: 1.0000e-07 - 101s/epoch - 129ms/step
Epoch 49/100
782/782 - 85s - loss: 3.7956 - output_1_loss: 2.4141 - output_2_loss: 0.0460 - output_1_Top-1 Accuracy: 0.3555 - output_1_Top-5 Accuracy: 0.7343 - val_loss: 3.9630 - val_output_1_loss: 2.7598 - val_output_2_loss: 0.0401 - val_output_1_Top-1 Accuracy: 0.2999 - val_output_1_Top-5 Accuracy: 0.6634 - lr: 1.0000e-07 - 85s/epoch - 109ms/step
Epoch 49: early stopping
<keras.src.engine.input_layer.InputLayer object at 0x7f1d3016e950>
<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7f1c89fb8b50>
<keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x7f1c89f507c0>
<keras.src.layers.core.activation.Activation object at 0x7f1c8a2bf580>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c89f6ce20>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1d30210ee0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c81502800>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c89d9c2e0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c8151b4f0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c81532a70>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c815252d0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c8152e9e0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c8152bdc0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c67425150>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c6740a590>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c81527d60>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cd49c97b0>
<keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7f1c89fba260>
<keras.src.layers.regularization.dropout.Dropout object at 0x7f1cd49ab220>
<keras.src.layers.core.dense.Dense object at 0x7f1cd49ab580>
<tempature_softmax_activation_layer.TempatureSoftmaxActivationLayer object at 0x7f1cd49aba00>
<keras.src.engine.input_layer.InputLayer object at 0x7f1d3016e950>
<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7f1c89fb8b50>
<keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x7f1c89f507c0>
<keras.src.layers.core.activation.Activation object at 0x7f1c8a2bf580>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c89f6ce20>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1d30210ee0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c81502800>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c89d9c2e0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c8151b4f0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c81532a70>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c815252d0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c8152e9e0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c8152bdc0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c67425150>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c6740a590>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c81527d60>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cd49c97b0>
<keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7f1c89fba260>
<keras.src.layers.regularization.dropout.Dropout object at 0x7f1cd49ab220>
<keras.src.layers.core.dense.Dense object at 0x7f1cd49ab580>
<tempature_softmax_activation_layer.TempatureSoftmaxActivationLayer object at 0x7f1cd49aba00>
<keras.src.engine.input_layer.InputLayer object at 0x7f1d3016e950>
<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7f1c89fb8b50>
<keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x7f1c89f507c0>
<keras.src.layers.core.activation.Activation object at 0x7f1c8a2bf580>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c89f6ce20>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1d30210ee0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c81502800>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c89d9c2e0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c8151b4f0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c81532a70>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c815252d0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c8152e9e0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c8152bdc0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c67425150>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c6740a590>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c81527d60>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cd49c97b0>
<keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7f1c89fba260>
<keras.src.layers.regularization.dropout.Dropout object at 0x7f1cd49ab220>
<keras.src.layers.core.dense.Dense object at 0x7f1cd49ab580>
<tempature_softmax_activation_layer.TempatureSoftmaxActivationLayer object at 0x7f1cd49aba00>
<keras.src.engine.input_layer.InputLayer object at 0x7f1d3016e950>
<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7f1c89fb8b50>
<keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x7f1c89f507c0>
<keras.src.layers.core.activation.Activation object at 0x7f1c8a2bf580>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c89f6ce20>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1d30210ee0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c81502800>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c89d9c2e0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c8151b4f0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c81532a70>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c815252d0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c8152e9e0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c8152bdc0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c67425150>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c6740a590>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c81527d60>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cd49c97b0>
<keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7f1c89fba260>
<keras.src.layers.regularization.dropout.Dropout object at 0x7f1cd49ab220>
<keras.src.layers.core.dense.Dense object at 0x7f1cd49ab580>
<tempature_softmax_activation_layer.TempatureSoftmaxActivationLayer object at 0x7f1cd49aba00>
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_2 (InputLayer)        [(None, 96, 96, 3)]       0         
                                                                 
 conv2d_14 (Conv2D)          (None, 47, 47, 24)        672       
                                                                 
 batch_normalization_40 (Ba  (None, 47, 47, 24)        96        
 tchNormalization)                                               
                                                                 
 activation_14 (Activation)  (None, 47, 47, 24)        0         
                                                                 
 linear_bottleneck_block_13  (None, 24, 24, 24)        1368      
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_14  (None, 24, 24, 24)        1368      
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_15  (None, 24, 24, 24)        1368      
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_16  (None, 24, 24, 24)        1368      
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_17  (None, 12, 12, 96)        4464      
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_18  (None, 12, 12, 96)        12384     
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_19  (None, 12, 12, 96)        12384     
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_20  (None, 12, 12, 96)        12384     
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_21  (None, 6, 6, 168)         20664     
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_22  (None, 6, 6, 168)         33768     
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_23  (None, 6, 6, 168)         33768     
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_24  (None, 3, 3, 192)         38256     
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_25  (None, 3, 3, 384)         83712     
  (LinearBottleneckBlock)                                        
                                                                 
 global_average_pooling2d_1  (None, 384)               0         
  (GlobalAveragePooling2D)                                       
                                                                 
 dropout_1 (Dropout)         (None, 384)               0         
                                                                 
 output_1 (Dense)            (None, 200)               77000     
                                                                 
 output_2 (TempatureSoftmax  (None, 200)               0         
 ActivationLayer)                                                
                                                                 
=================================================================
Total params: 335024 (1.28 MB)
Trainable params: 326336 (1.24 MB)
Non-trainable params: 8688 (33.94 KB)
_________________________________________________________________
Epoch 1/100
782/782 - 99s - loss: 4.5619 - output_1_loss: 3.0398 - output_2_loss: 0.0507 - output_1_Top-1 Accuracy: 0.2547 - output_1_Top-5 Accuracy: 0.5996 - val_loss: 5.4264 - val_output_1_loss: 4.0148 - val_output_2_loss: 0.0471 - val_output_1_Top-1 Accuracy: 0.1533 - val_output_1_Top-5 Accuracy: 0.4368 - lr: 0.1000 - 99s/epoch - 126ms/step
Epoch 2/100
782/782 - 77s - loss: 4.4374 - output_1_loss: 2.9487 - output_2_loss: 0.0496 - output_1_Top-1 Accuracy: 0.2695 - output_1_Top-5 Accuracy: 0.6195 - val_loss: 4.7020 - val_output_1_loss: 3.3574 - val_output_2_loss: 0.0448 - val_output_1_Top-1 Accuracy: 0.2109 - val_output_1_Top-5 Accuracy: 0.5325 - lr: 0.1000 - 77s/epoch - 98ms/step
Epoch 3/100
782/782 - 79s - loss: 4.3655 - output_1_loss: 2.8978 - output_2_loss: 0.0489 - output_1_Top-1 Accuracy: 0.2746 - output_1_Top-5 Accuracy: 0.6313 - val_loss: 4.6588 - val_output_1_loss: 3.3102 - val_output_2_loss: 0.0450 - val_output_1_Top-1 Accuracy: 0.2281 - val_output_1_Top-5 Accuracy: 0.5473 - lr: 0.1000 - 79s/epoch - 101ms/step
Epoch 4/100
782/782 - 79s - loss: 4.3154 - output_1_loss: 2.8672 - output_2_loss: 0.0483 - output_1_Top-1 Accuracy: 0.2786 - output_1_Top-5 Accuracy: 0.6379 - val_loss: 4.4745 - val_output_1_loss: 3.1987 - val_output_2_loss: 0.0425 - val_output_1_Top-1 Accuracy: 0.2330 - val_output_1_Top-5 Accuracy: 0.5711 - lr: 0.1000 - 79s/epoch - 102ms/step
Epoch 5/100
782/782 - 79s - loss: 4.2684 - output_1_loss: 2.8353 - output_2_loss: 0.0478 - output_1_Top-1 Accuracy: 0.2816 - output_1_Top-5 Accuracy: 0.6472 - val_loss: 4.4536 - val_output_1_loss: 3.2014 - val_output_2_loss: 0.0417 - val_output_1_Top-1 Accuracy: 0.2337 - val_output_1_Top-5 Accuracy: 0.5720 - lr: 0.1000 - 79s/epoch - 102ms/step
Epoch 6/100
782/782 - 79s - loss: 4.2335 - output_1_loss: 2.8111 - output_2_loss: 0.0474 - output_1_Top-1 Accuracy: 0.2848 - output_1_Top-5 Accuracy: 0.6508 - val_loss: 4.5927 - val_output_1_loss: 3.2747 - val_output_2_loss: 0.0439 - val_output_1_Top-1 Accuracy: 0.2274 - val_output_1_Top-5 Accuracy: 0.5518 - lr: 0.1000 - 79s/epoch - 102ms/step
Epoch 7/100
782/782 - 80s - loss: 4.1960 - output_1_loss: 2.7886 - output_2_loss: 0.0469 - output_1_Top-1 Accuracy: 0.2878 - output_1_Top-5 Accuracy: 0.6545 - val_loss: 4.4464 - val_output_1_loss: 3.2039 - val_output_2_loss: 0.0414 - val_output_1_Top-1 Accuracy: 0.2264 - val_output_1_Top-5 Accuracy: 0.5755 - lr: 0.1000 - 80s/epoch - 102ms/step
Epoch 8/100
782/782 - 80s - loss: 4.1577 - output_1_loss: 2.7612 - output_2_loss: 0.0466 - output_1_Top-1 Accuracy: 0.2889 - output_1_Top-5 Accuracy: 0.6615 - val_loss: 4.4085 - val_output_1_loss: 3.1423 - val_output_2_loss: 0.0422 - val_output_1_Top-1 Accuracy: 0.2352 - val_output_1_Top-5 Accuracy: 0.5854 - lr: 0.1000 - 80s/epoch - 102ms/step
Epoch 9/100
782/782 - 78s - loss: 4.1328 - output_1_loss: 2.7434 - output_2_loss: 0.0463 - output_1_Top-1 Accuracy: 0.2916 - output_1_Top-5 Accuracy: 0.6664 - val_loss: 4.4588 - val_output_1_loss: 3.2188 - val_output_2_loss: 0.0413 - val_output_1_Top-1 Accuracy: 0.2299 - val_output_1_Top-5 Accuracy: 0.5756 - lr: 0.1000 - 78s/epoch - 99ms/step
Epoch 10/100
782/782 - 77s - loss: 4.1044 - output_1_loss: 2.7242 - output_2_loss: 0.0460 - output_1_Top-1 Accuracy: 0.2937 - output_1_Top-5 Accuracy: 0.6702 - val_loss: 4.3701 - val_output_1_loss: 3.1547 - val_output_2_loss: 0.0405 - val_output_1_Top-1 Accuracy: 0.2332 - val_output_1_Top-5 Accuracy: 0.5886 - lr: 0.1000 - 77s/epoch - 99ms/step
Epoch 11/100
782/782 - 82s - loss: 4.0788 - output_1_loss: 2.7077 - output_2_loss: 0.0457 - output_1_Top-1 Accuracy: 0.2946 - output_1_Top-5 Accuracy: 0.6758 - val_loss: 4.3921 - val_output_1_loss: 3.1541 - val_output_2_loss: 0.0413 - val_output_1_Top-1 Accuracy: 0.2349 - val_output_1_Top-5 Accuracy: 0.5847 - lr: 0.1000 - 82s/epoch - 104ms/step
Epoch 12/100
782/782 - 80s - loss: 4.0521 - output_1_loss: 2.6880 - output_2_loss: 0.0455 - output_1_Top-1 Accuracy: 0.2990 - output_1_Top-5 Accuracy: 0.6786 - val_loss: 4.3859 - val_output_1_loss: 3.1312 - val_output_2_loss: 0.0418 - val_output_1_Top-1 Accuracy: 0.2392 - val_output_1_Top-5 Accuracy: 0.5850 - lr: 0.1000 - 80s/epoch - 102ms/step
Epoch 13/100

Epoch 13: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.
782/782 - 80s - loss: 4.0340 - output_1_loss: 2.6767 - output_2_loss: 0.0452 - output_1_Top-1 Accuracy: 0.2979 - output_1_Top-5 Accuracy: 0.6806 - val_loss: 4.4653 - val_output_1_loss: 3.2086 - val_output_2_loss: 0.0419 - val_output_1_Top-1 Accuracy: 0.2282 - val_output_1_Top-5 Accuracy: 0.5675 - lr: 0.1000 - 80s/epoch - 102ms/step
Epoch 14/100
782/782 - 79s - loss: 3.7877 - output_1_loss: 2.4810 - output_2_loss: 0.0436 - output_1_Top-1 Accuracy: 0.3316 - output_1_Top-5 Accuracy: 0.7228 - val_loss: 3.9654 - val_output_1_loss: 2.8243 - val_output_2_loss: 0.0380 - val_output_1_Top-1 Accuracy: 0.2808 - val_output_1_Top-5 Accuracy: 0.6557 - lr: 0.0100 - 79s/epoch - 102ms/step
Epoch 15/100
782/782 - 82s - loss: 3.6981 - output_1_loss: 2.4129 - output_2_loss: 0.0428 - output_1_Top-1 Accuracy: 0.3427 - output_1_Top-5 Accuracy: 0.7366 - val_loss: 3.9559 - val_output_1_loss: 2.8270 - val_output_2_loss: 0.0376 - val_output_1_Top-1 Accuracy: 0.2757 - val_output_1_Top-5 Accuracy: 0.6609 - lr: 0.0100 - 82s/epoch - 104ms/step
Epoch 16/100
782/782 - 78s - loss: 3.6701 - output_1_loss: 2.3911 - output_2_loss: 0.0426 - output_1_Top-1 Accuracy: 0.3453 - output_1_Top-5 Accuracy: 0.7427 - val_loss: 3.9457 - val_output_1_loss: 2.8131 - val_output_2_loss: 0.0378 - val_output_1_Top-1 Accuracy: 0.2847 - val_output_1_Top-5 Accuracy: 0.6594 - lr: 0.0100 - 78s/epoch - 100ms/step
Epoch 17/100
782/782 - 79s - loss: 3.6441 - output_1_loss: 2.3662 - output_2_loss: 0.0426 - output_1_Top-1 Accuracy: 0.3496 - output_1_Top-5 Accuracy: 0.7474 - val_loss: 3.9525 - val_output_1_loss: 2.8212 - val_output_2_loss: 0.0377 - val_output_1_Top-1 Accuracy: 0.2812 - val_output_1_Top-5 Accuracy: 0.6571 - lr: 0.0100 - 79s/epoch - 102ms/step
Epoch 18/100
782/782 - 74s - loss: 3.6302 - output_1_loss: 2.3589 - output_2_loss: 0.0424 - output_1_Top-1 Accuracy: 0.3487 - output_1_Top-5 Accuracy: 0.7492 - val_loss: 3.9573 - val_output_1_loss: 2.8233 - val_output_2_loss: 0.0378 - val_output_1_Top-1 Accuracy: 0.2796 - val_output_1_Top-5 Accuracy: 0.6583 - lr: 0.0100 - 74s/epoch - 94ms/step
Epoch 19/100

Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.
782/782 - 82s - loss: 3.6152 - output_1_loss: 2.3477 - output_2_loss: 0.0422 - output_1_Top-1 Accuracy: 0.3495 - output_1_Top-5 Accuracy: 0.7505 - val_loss: 3.9520 - val_output_1_loss: 2.8228 - val_output_2_loss: 0.0376 - val_output_1_Top-1 Accuracy: 0.2842 - val_output_1_Top-5 Accuracy: 0.6588 - lr: 0.0100 - 82s/epoch - 105ms/step
Epoch 20/100
782/782 - 79s - loss: 3.5822 - output_1_loss: 2.3185 - output_2_loss: 0.0421 - output_1_Top-1 Accuracy: 0.3556 - output_1_Top-5 Accuracy: 0.7567 - val_loss: 3.9448 - val_output_1_loss: 2.8202 - val_output_2_loss: 0.0375 - val_output_1_Top-1 Accuracy: 0.2805 - val_output_1_Top-5 Accuracy: 0.6621 - lr: 1.0000e-03 - 79s/epoch - 102ms/step
Epoch 21/100
782/782 - 80s - loss: 3.5737 - output_1_loss: 2.3117 - output_2_loss: 0.0421 - output_1_Top-1 Accuracy: 0.3588 - output_1_Top-5 Accuracy: 0.7581 - val_loss: 3.9429 - val_output_1_loss: 2.8174 - val_output_2_loss: 0.0375 - val_output_1_Top-1 Accuracy: 0.2798 - val_output_1_Top-5 Accuracy: 0.6599 - lr: 1.0000e-03 - 80s/epoch - 102ms/step
Epoch 22/100
782/782 - 74s - loss: 3.5706 - output_1_loss: 2.3078 - output_2_loss: 0.0421 - output_1_Top-1 Accuracy: 0.3598 - output_1_Top-5 Accuracy: 0.7601 - val_loss: 3.9431 - val_output_1_loss: 2.8183 - val_output_2_loss: 0.0375 - val_output_1_Top-1 Accuracy: 0.2813 - val_output_1_Top-5 Accuracy: 0.6611 - lr: 1.0000e-03 - 74s/epoch - 94ms/step
Epoch 23/100
782/782 - 79s - loss: 3.5697 - output_1_loss: 2.3073 - output_2_loss: 0.0421 - output_1_Top-1 Accuracy: 0.3574 - output_1_Top-5 Accuracy: 0.7579 - val_loss: 3.9450 - val_output_1_loss: 2.8205 - val_output_2_loss: 0.0375 - val_output_1_Top-1 Accuracy: 0.2785 - val_output_1_Top-5 Accuracy: 0.6593 - lr: 1.0000e-03 - 79s/epoch - 102ms/step
Epoch 24/100

Epoch 24: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.
782/782 - 64s - loss: 3.5654 - output_1_loss: 2.3036 - output_2_loss: 0.0421 - output_1_Top-1 Accuracy: 0.3591 - output_1_Top-5 Accuracy: 0.7593 - val_loss: 3.9450 - val_output_1_loss: 2.8189 - val_output_2_loss: 0.0375 - val_output_1_Top-1 Accuracy: 0.2804 - val_output_1_Top-5 Accuracy: 0.6601 - lr: 1.0000e-03 - 64s/epoch - 81ms/step
Epoch 25/100
782/782 - 58s - loss: 3.5647 - output_1_loss: 2.3055 - output_2_loss: 0.0420 - output_1_Top-1 Accuracy: 0.3603 - output_1_Top-5 Accuracy: 0.7589 - val_loss: 3.9451 - val_output_1_loss: 2.8195 - val_output_2_loss: 0.0375 - val_output_1_Top-1 Accuracy: 0.2795 - val_output_1_Top-5 Accuracy: 0.6585 - lr: 1.0000e-04 - 58s/epoch - 74ms/step
Epoch 26/100
782/782 - 58s - loss: 3.5626 - output_1_loss: 2.3024 - output_2_loss: 0.0420 - output_1_Top-1 Accuracy: 0.3586 - output_1_Top-5 Accuracy: 0.7597 - val_loss: 3.9445 - val_output_1_loss: 2.8195 - val_output_2_loss: 0.0375 - val_output_1_Top-1 Accuracy: 0.2787 - val_output_1_Top-5 Accuracy: 0.6592 - lr: 1.0000e-04 - 58s/epoch - 74ms/step
Epoch 27/100

Epoch 27: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.
782/782 - 58s - loss: 3.5621 - output_1_loss: 2.3026 - output_2_loss: 0.0420 - output_1_Top-1 Accuracy: 0.3585 - output_1_Top-5 Accuracy: 0.7593 - val_loss: 3.9452 - val_output_1_loss: 2.8207 - val_output_2_loss: 0.0375 - val_output_1_Top-1 Accuracy: 0.2785 - val_output_1_Top-5 Accuracy: 0.6607 - lr: 1.0000e-04 - 58s/epoch - 75ms/step
Epoch 28/100
782/782 - 58s - loss: 3.5634 - output_1_loss: 2.3030 - output_2_loss: 0.0420 - output_1_Top-1 Accuracy: 0.3594 - output_1_Top-5 Accuracy: 0.7611 - val_loss: 3.9439 - val_output_1_loss: 2.8195 - val_output_2_loss: 0.0375 - val_output_1_Top-1 Accuracy: 0.2795 - val_output_1_Top-5 Accuracy: 0.6601 - lr: 1.0000e-05 - 58s/epoch - 74ms/step
Epoch 29/100
782/782 - 58s - loss: 3.5595 - output_1_loss: 2.3004 - output_2_loss: 0.0420 - output_1_Top-1 Accuracy: 0.3588 - output_1_Top-5 Accuracy: 0.7617 - val_loss: 3.9459 - val_output_1_loss: 2.8217 - val_output_2_loss: 0.0375 - val_output_1_Top-1 Accuracy: 0.2787 - val_output_1_Top-5 Accuracy: 0.6595 - lr: 1.0000e-05 - 58s/epoch - 75ms/step
Epoch 30/100

Epoch 30: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.
782/782 - 58s - loss: 3.5641 - output_1_loss: 2.3025 - output_2_loss: 0.0421 - output_1_Top-1 Accuracy: 0.3591 - output_1_Top-5 Accuracy: 0.7596 - val_loss: 3.9442 - val_output_1_loss: 2.8193 - val_output_2_loss: 0.0375 - val_output_1_Top-1 Accuracy: 0.2796 - val_output_1_Top-5 Accuracy: 0.6595 - lr: 1.0000e-05 - 58s/epoch - 74ms/step
Epoch 31/100
782/782 - 57s - loss: 3.5660 - output_1_loss: 2.3059 - output_2_loss: 0.0420 - output_1_Top-1 Accuracy: 0.3609 - output_1_Top-5 Accuracy: 0.7599 - val_loss: 3.9453 - val_output_1_loss: 2.8201 - val_output_2_loss: 0.0375 - val_output_1_Top-1 Accuracy: 0.2787 - val_output_1_Top-5 Accuracy: 0.6593 - lr: 1.0000e-06 - 57s/epoch - 73ms/step
Epoch 31: early stopping
<keras.src.engine.input_layer.InputLayer object at 0x7f1c81531f90>
<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7f1c878a5660>
<keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x7f1c84fb64a0>
<keras.src.layers.core.activation.Activation object at 0x7f1c879328f0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85649f60>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c84fb5e40>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c852e76a0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c852887f0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85282080>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c87849450>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c87a57160>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c852aebf0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85115510>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85274b20>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c879e8100>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85116d10>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c852977c0>
<keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7f1c80f20c70>
<keras.src.layers.regularization.dropout.Dropout object at 0x7f1c852bfee0>
<keras.src.layers.core.dense.Dense object at 0x7f1c852d09d0>
<tempature_softmax_activation_layer.TempatureSoftmaxActivationLayer object at 0x7f1c852d2980>
<keras.src.engine.input_layer.InputLayer object at 0x7f1c81531f90>
<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7f1c878a5660>
<keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x7f1c84fb64a0>
<keras.src.layers.core.activation.Activation object at 0x7f1c879328f0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85649f60>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c84fb5e40>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c852e76a0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c852887f0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85282080>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c87849450>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c87a57160>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c852aebf0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85115510>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85274b20>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c879e8100>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85116d10>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c852977c0>
<keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7f1c80f20c70>
<keras.src.layers.regularization.dropout.Dropout object at 0x7f1c852bfee0>
<keras.src.layers.core.dense.Dense object at 0x7f1c852d09d0>
<tempature_softmax_activation_layer.TempatureSoftmaxActivationLayer object at 0x7f1c852d2980>
<keras.src.engine.input_layer.InputLayer object at 0x7f1c81531f90>
<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7f1c878a5660>
<keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x7f1c84fb64a0>
<keras.src.layers.core.activation.Activation object at 0x7f1c879328f0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85649f60>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c84fb5e40>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c852e76a0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c852887f0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85282080>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c87849450>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c87a57160>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c852aebf0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85115510>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85274b20>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c879e8100>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85116d10>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c852977c0>
<keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7f1c80f20c70>
<keras.src.layers.regularization.dropout.Dropout object at 0x7f1c852bfee0>
<keras.src.layers.core.dense.Dense object at 0x7f1c852d09d0>
<tempature_softmax_activation_layer.TempatureSoftmaxActivationLayer object at 0x7f1c852d2980>
<keras.src.engine.input_layer.InputLayer object at 0x7f1c81531f90>
<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7f1c878a5660>
<keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x7f1c84fb64a0>
<keras.src.layers.core.activation.Activation object at 0x7f1c879328f0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85649f60>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c84fb5e40>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c852e76a0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c852887f0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85282080>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c87849450>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c87a57160>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c852aebf0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85115510>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85274b20>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c879e8100>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85116d10>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c852977c0>
<keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7f1c80f20c70>
<keras.src.layers.regularization.dropout.Dropout object at 0x7f1c852bfee0>
<keras.src.layers.core.dense.Dense object at 0x7f1c852d09d0>
<tempature_softmax_activation_layer.TempatureSoftmaxActivationLayer object at 0x7f1c852d2980>
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_3 (InputLayer)        [(None, 64, 64, 3)]       0         
                                                                 
 conv2d_28 (Conv2D)          (None, 31, 31, 24)        672       
                                                                 
 batch_normalization_80 (Ba  (None, 31, 31, 24)        96        
 tchNormalization)                                               
                                                                 
 activation_28 (Activation)  (None, 31, 31, 24)        0         
                                                                 
 linear_bottleneck_block_26  (None, 16, 16, 24)        1368      
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_27  (None, 16, 16, 24)        1368      
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_28  (None, 16, 16, 24)        1368      
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_29  (None, 16, 16, 24)        1368      
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_30  (None, 8, 8, 96)          4464      
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_31  (None, 8, 8, 96)          12384     
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_32  (None, 8, 8, 96)          12384     
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_33  (None, 8, 8, 96)          12384     
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_34  (None, 4, 4, 168)         20664     
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_35  (None, 4, 4, 168)         33768     
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_36  (None, 4, 4, 168)         33768     
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_37  (None, 2, 2, 192)         38256     
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_38  (None, 2, 2, 384)         83712     
  (LinearBottleneckBlock)                                        
                                                                 
 global_average_pooling2d_2  (None, 384)               0         
  (GlobalAveragePooling2D)                                       
                                                                 
 dropout_2 (Dropout)         (None, 384)               0         
                                                                 
 output_1 (Dense)            (None, 200)               77000     
                                                                 
 output_2 (TempatureSoftmax  (None, 200)               0         
 ActivationLayer)                                                
                                                                 
=================================================================
Total params: 335024 (1.28 MB)
Trainable params: 326336 (1.24 MB)
Non-trainable params: 8688 (33.94 KB)
_________________________________________________________________
Epoch 1/100
782/782 - 55s - loss: 4.9668 - output_1_loss: 3.3888 - output_2_loss: 0.0526 - output_1_Top-1 Accuracy: 0.2057 - output_1_Top-5 Accuracy: 0.5202 - val_loss: 5.0731 - val_output_1_loss: 3.6589 - val_output_2_loss: 0.0471 - val_output_1_Top-1 Accuracy: 0.1839 - val_output_1_Top-5 Accuracy: 0.4620 - lr: 0.1000 - 55s/epoch - 70ms/step
Epoch 2/100
782/782 - 38s - loss: 4.7276 - output_1_loss: 3.2016 - output_2_loss: 0.0509 - output_1_Top-1 Accuracy: 0.2305 - output_1_Top-5 Accuracy: 0.5629 - val_loss: 4.7401 - val_output_1_loss: 3.4208 - val_output_2_loss: 0.0440 - val_output_1_Top-1 Accuracy: 0.2072 - val_output_1_Top-5 Accuracy: 0.5219 - lr: 0.1000 - 38s/epoch - 49ms/step
Epoch 3/100
782/782 - 39s - loss: 4.6373 - output_1_loss: 3.1293 - output_2_loss: 0.0503 - output_1_Top-1 Accuracy: 0.2414 - output_1_Top-5 Accuracy: 0.5787 - val_loss: 4.8263 - val_output_1_loss: 3.4920 - val_output_2_loss: 0.0445 - val_output_1_Top-1 Accuracy: 0.2019 - val_output_1_Top-5 Accuracy: 0.5180 - lr: 0.1000 - 39s/epoch - 49ms/step
Epoch 4/100
782/782 - 38s - loss: 4.5532 - output_1_loss: 3.0715 - output_2_loss: 0.0494 - output_1_Top-1 Accuracy: 0.2474 - output_1_Top-5 Accuracy: 0.5920 - val_loss: 4.7849 - val_output_1_loss: 3.4030 - val_output_2_loss: 0.0461 - val_output_1_Top-1 Accuracy: 0.2081 - val_output_1_Top-5 Accuracy: 0.5078 - lr: 0.1000 - 38s/epoch - 49ms/step
Epoch 5/100
782/782 - 38s - loss: 4.4899 - output_1_loss: 3.0213 - output_2_loss: 0.0490 - output_1_Top-1 Accuracy: 0.2546 - output_1_Top-5 Accuracy: 0.6035 - val_loss: 4.6293 - val_output_1_loss: 3.3146 - val_output_2_loss: 0.0438 - val_output_1_Top-1 Accuracy: 0.2209 - val_output_1_Top-5 Accuracy: 0.5378 - lr: 0.1000 - 38s/epoch - 49ms/step
Epoch 6/100
782/782 - 38s - loss: 4.4283 - output_1_loss: 2.9792 - output_2_loss: 0.0483 - output_1_Top-1 Accuracy: 0.2574 - output_1_Top-5 Accuracy: 0.6140 - val_loss: 4.5861 - val_output_1_loss: 3.2994 - val_output_2_loss: 0.0429 - val_output_1_Top-1 Accuracy: 0.2243 - val_output_1_Top-5 Accuracy: 0.5456 - lr: 0.1000 - 38s/epoch - 49ms/step
Epoch 7/100
782/782 - 38s - loss: 4.3844 - output_1_loss: 2.9442 - output_2_loss: 0.0480 - output_1_Top-1 Accuracy: 0.2646 - output_1_Top-5 Accuracy: 0.6209 - val_loss: 4.7026 - val_output_1_loss: 3.3953 - val_output_2_loss: 0.0436 - val_output_1_Top-1 Accuracy: 0.2042 - val_output_1_Top-5 Accuracy: 0.5224 - lr: 0.1000 - 38s/epoch - 49ms/step
Epoch 8/100
782/782 - 39s - loss: 4.3421 - output_1_loss: 2.9113 - output_2_loss: 0.0477 - output_1_Top-1 Accuracy: 0.2678 - output_1_Top-5 Accuracy: 0.6276 - val_loss: 4.4849 - val_output_1_loss: 3.2147 - val_output_2_loss: 0.0423 - val_output_1_Top-1 Accuracy: 0.2299 - val_output_1_Top-5 Accuracy: 0.5620 - lr: 0.1000 - 39s/epoch - 49ms/step
Epoch 9/100
782/782 - 38s - loss: 4.3118 - output_1_loss: 2.8905 - output_2_loss: 0.0474 - output_1_Top-1 Accuracy: 0.2698 - output_1_Top-5 Accuracy: 0.6341 - val_loss: 4.5067 - val_output_1_loss: 3.2622 - val_output_2_loss: 0.0415 - val_output_1_Top-1 Accuracy: 0.2224 - val_output_1_Top-5 Accuracy: 0.5582 - lr: 0.1000 - 38s/epoch - 49ms/step
Epoch 10/100
782/782 - 38s - loss: 4.2707 - output_1_loss: 2.8623 - output_2_loss: 0.0469 - output_1_Top-1 Accuracy: 0.2718 - output_1_Top-5 Accuracy: 0.6397 - val_loss: 4.4695 - val_output_1_loss: 3.1996 - val_output_2_loss: 0.0423 - val_output_1_Top-1 Accuracy: 0.2346 - val_output_1_Top-5 Accuracy: 0.5675 - lr: 0.1000 - 38s/epoch - 49ms/step
Epoch 11/100
782/782 - 39s - loss: 4.2440 - output_1_loss: 2.8466 - output_2_loss: 0.0466 - output_1_Top-1 Accuracy: 0.2755 - output_1_Top-5 Accuracy: 0.6432 - val_loss: 4.4810 - val_output_1_loss: 3.2374 - val_output_2_loss: 0.0415 - val_output_1_Top-1 Accuracy: 0.2315 - val_output_1_Top-5 Accuracy: 0.5659 - lr: 0.1000 - 39s/epoch - 49ms/step
Epoch 12/100
782/782 - 39s - loss: 4.2150 - output_1_loss: 2.8200 - output_2_loss: 0.0465 - output_1_Top-1 Accuracy: 0.2783 - output_1_Top-5 Accuracy: 0.6482 - val_loss: 4.6595 - val_output_1_loss: 3.3282 - val_output_2_loss: 0.0444 - val_output_1_Top-1 Accuracy: 0.2217 - val_output_1_Top-5 Accuracy: 0.5362 - lr: 0.1000 - 39s/epoch - 49ms/step
Epoch 13/100

Epoch 13: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.
782/782 - 39s - loss: 4.2025 - output_1_loss: 2.8094 - output_2_loss: 0.0464 - output_1_Top-1 Accuracy: 0.2807 - output_1_Top-5 Accuracy: 0.6518 - val_loss: 4.8750 - val_output_1_loss: 3.5489 - val_output_2_loss: 0.0442 - val_output_1_Top-1 Accuracy: 0.1907 - val_output_1_Top-5 Accuracy: 0.5087 - lr: 0.1000 - 39s/epoch - 49ms/step
Epoch 14/100
782/782 - 38s - loss: 3.9623 - output_1_loss: 2.6226 - output_2_loss: 0.0447 - output_1_Top-1 Accuracy: 0.3084 - output_1_Top-5 Accuracy: 0.6924 - val_loss: 4.0964 - val_output_1_loss: 2.9284 - val_output_2_loss: 0.0389 - val_output_1_Top-1 Accuracy: 0.2716 - val_output_1_Top-5 Accuracy: 0.6306 - lr: 0.0100 - 38s/epoch - 49ms/step
Epoch 15/100
782/782 - 38s - loss: 3.8595 - output_1_loss: 2.5462 - output_2_loss: 0.0438 - output_1_Top-1 Accuracy: 0.3198 - output_1_Top-5 Accuracy: 0.7077 - val_loss: 4.0956 - val_output_1_loss: 2.9345 - val_output_2_loss: 0.0387 - val_output_1_Top-1 Accuracy: 0.2732 - val_output_1_Top-5 Accuracy: 0.6312 - lr: 0.0100 - 38s/epoch - 49ms/step
Epoch 16/100
782/782 - 38s - loss: 3.8296 - output_1_loss: 2.5235 - output_2_loss: 0.0435 - output_1_Top-1 Accuracy: 0.3223 - output_1_Top-5 Accuracy: 0.7130 - val_loss: 4.0815 - val_output_1_loss: 2.9222 - val_output_2_loss: 0.0386 - val_output_1_Top-1 Accuracy: 0.2705 - val_output_1_Top-5 Accuracy: 0.6318 - lr: 0.0100 - 38s/epoch - 49ms/step
Epoch 17/100
782/782 - 38s - loss: 3.8042 - output_1_loss: 2.5036 - output_2_loss: 0.0434 - output_1_Top-1 Accuracy: 0.3230 - output_1_Top-5 Accuracy: 0.7176 - val_loss: 4.0815 - val_output_1_loss: 2.9253 - val_output_2_loss: 0.0385 - val_output_1_Top-1 Accuracy: 0.2674 - val_output_1_Top-5 Accuracy: 0.6367 - lr: 0.0100 - 38s/epoch - 49ms/step
Epoch 18/100
782/782 - 38s - loss: 3.7860 - output_1_loss: 2.4898 - output_2_loss: 0.0432 - output_1_Top-1 Accuracy: 0.3266 - output_1_Top-5 Accuracy: 0.7202 - val_loss: 4.0856 - val_output_1_loss: 2.9297 - val_output_2_loss: 0.0385 - val_output_1_Top-1 Accuracy: 0.2669 - val_output_1_Top-5 Accuracy: 0.6305 - lr: 0.0100 - 38s/epoch - 49ms/step
Epoch 19/100

Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.
782/782 - 38s - loss: 3.7726 - output_1_loss: 2.4802 - output_2_loss: 0.0431 - output_1_Top-1 Accuracy: 0.3280 - output_1_Top-5 Accuracy: 0.7205 - val_loss: 4.1008 - val_output_1_loss: 2.9452 - val_output_2_loss: 0.0385 - val_output_1_Top-1 Accuracy: 0.2670 - val_output_1_Top-5 Accuracy: 0.6303 - lr: 0.0100 - 38s/epoch - 49ms/step
Epoch 20/100
782/782 - 38s - loss: 3.7320 - output_1_loss: 2.4470 - output_2_loss: 0.0428 - output_1_Top-1 Accuracy: 0.3336 - output_1_Top-5 Accuracy: 0.7290 - val_loss: 4.0832 - val_output_1_loss: 2.9330 - val_output_2_loss: 0.0383 - val_output_1_Top-1 Accuracy: 0.2642 - val_output_1_Top-5 Accuracy: 0.6331 - lr: 1.0000e-03 - 38s/epoch - 49ms/step
Epoch 21/100
782/782 - 38s - loss: 3.7335 - output_1_loss: 2.4473 - output_2_loss: 0.0429 - output_1_Top-1 Accuracy: 0.3336 - output_1_Top-5 Accuracy: 0.7275 - val_loss: 4.0801 - val_output_1_loss: 2.9295 - val_output_2_loss: 0.0384 - val_output_1_Top-1 Accuracy: 0.2648 - val_output_1_Top-5 Accuracy: 0.6338 - lr: 1.0000e-03 - 38s/epoch - 49ms/step
Epoch 22/100
782/782 - 39s - loss: 3.7278 - output_1_loss: 2.4424 - output_2_loss: 0.0428 - output_1_Top-1 Accuracy: 0.3359 - output_1_Top-5 Accuracy: 0.7305 - val_loss: 4.0822 - val_output_1_loss: 2.9322 - val_output_2_loss: 0.0383 - val_output_1_Top-1 Accuracy: 0.2641 - val_output_1_Top-5 Accuracy: 0.6342 - lr: 1.0000e-03 - 39s/epoch - 49ms/step
Epoch 23/100
782/782 - 39s - loss: 3.7248 - output_1_loss: 2.4400 - output_2_loss: 0.0428 - output_1_Top-1 Accuracy: 0.3339 - output_1_Top-5 Accuracy: 0.7288 - val_loss: 4.0796 - val_output_1_loss: 2.9290 - val_output_2_loss: 0.0384 - val_output_1_Top-1 Accuracy: 0.2651 - val_output_1_Top-5 Accuracy: 0.6344 - lr: 1.0000e-03 - 39s/epoch - 49ms/step
Epoch 24/100
782/782 - 38s - loss: 3.7288 - output_1_loss: 2.4435 - output_2_loss: 0.0428 - output_1_Top-1 Accuracy: 0.3341 - output_1_Top-5 Accuracy: 0.7300 - val_loss: 4.0792 - val_output_1_loss: 2.9286 - val_output_2_loss: 0.0384 - val_output_1_Top-1 Accuracy: 0.2652 - val_output_1_Top-5 Accuracy: 0.6342 - lr: 1.0000e-03 - 38s/epoch - 49ms/step
Epoch 25/100
782/782 - 38s - loss: 3.7206 - output_1_loss: 2.4356 - output_2_loss: 0.0428 - output_1_Top-1 Accuracy: 0.3354 - output_1_Top-5 Accuracy: 0.7296 - val_loss: 4.0843 - val_output_1_loss: 2.9343 - val_output_2_loss: 0.0383 - val_output_1_Top-1 Accuracy: 0.2635 - val_output_1_Top-5 Accuracy: 0.6341 - lr: 1.0000e-03 - 38s/epoch - 49ms/step
Epoch 26/100
782/782 - 38s - loss: 3.7226 - output_1_loss: 2.4383 - output_2_loss: 0.0428 - output_1_Top-1 Accuracy: 0.3357 - output_1_Top-5 Accuracy: 0.7299 - val_loss: 4.0823 - val_output_1_loss: 2.9327 - val_output_2_loss: 0.0383 - val_output_1_Top-1 Accuracy: 0.2639 - val_output_1_Top-5 Accuracy: 0.6349 - lr: 1.0000e-03 - 38s/epoch - 49ms/step
Epoch 27/100

Epoch 27: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.
782/782 - 39s - loss: 3.7198 - output_1_loss: 2.4367 - output_2_loss: 0.0428 - output_1_Top-1 Accuracy: 0.3334 - output_1_Top-5 Accuracy: 0.7293 - val_loss: 4.0806 - val_output_1_loss: 2.9296 - val_output_2_loss: 0.0384 - val_output_1_Top-1 Accuracy: 0.2630 - val_output_1_Top-5 Accuracy: 0.6352 - lr: 1.0000e-03 - 39s/epoch - 49ms/step
Epoch 28/100
782/782 - 39s - loss: 3.7099 - output_1_loss: 2.4284 - output_2_loss: 0.0427 - output_1_Top-1 Accuracy: 0.3362 - output_1_Top-5 Accuracy: 0.7316 - val_loss: 4.0778 - val_output_1_loss: 2.9277 - val_output_2_loss: 0.0383 - val_output_1_Top-1 Accuracy: 0.2643 - val_output_1_Top-5 Accuracy: 0.6339 - lr: 1.0000e-04 - 39s/epoch - 49ms/step
Epoch 29/100
782/782 - 38s - loss: 3.7125 - output_1_loss: 2.4302 - output_2_loss: 0.0427 - output_1_Top-1 Accuracy: 0.3355 - output_1_Top-5 Accuracy: 0.7320 - val_loss: 4.0815 - val_output_1_loss: 2.9320 - val_output_2_loss: 0.0383 - val_output_1_Top-1 Accuracy: 0.2626 - val_output_1_Top-5 Accuracy: 0.6341 - lr: 1.0000e-04 - 38s/epoch - 49ms/step
Epoch 30/100
782/782 - 38s - loss: 3.7098 - output_1_loss: 2.4284 - output_2_loss: 0.0427 - output_1_Top-1 Accuracy: 0.3383 - output_1_Top-5 Accuracy: 0.7315 - val_loss: 4.0802 - val_output_1_loss: 2.9300 - val_output_2_loss: 0.0383 - val_output_1_Top-1 Accuracy: 0.2628 - val_output_1_Top-5 Accuracy: 0.6356 - lr: 1.0000e-04 - 38s/epoch - 49ms/step
Epoch 31/100

Epoch 31: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.
782/782 - 38s - loss: 3.7081 - output_1_loss: 2.4274 - output_2_loss: 0.0427 - output_1_Top-1 Accuracy: 0.3345 - output_1_Top-5 Accuracy: 0.7337 - val_loss: 4.0806 - val_output_1_loss: 2.9307 - val_output_2_loss: 0.0383 - val_output_1_Top-1 Accuracy: 0.2632 - val_output_1_Top-5 Accuracy: 0.6338 - lr: 1.0000e-04 - 38s/epoch - 49ms/step
Epoch 32/100
782/782 - 38s - loss: 3.7154 - output_1_loss: 2.4331 - output_2_loss: 0.0427 - output_1_Top-1 Accuracy: 0.3338 - output_1_Top-5 Accuracy: 0.7315 - val_loss: 4.0840 - val_output_1_loss: 2.9344 - val_output_2_loss: 0.0383 - val_output_1_Top-1 Accuracy: 0.2623 - val_output_1_Top-5 Accuracy: 0.6346 - lr: 1.0000e-05 - 38s/epoch - 49ms/step
Epoch 33/100
782/782 - 38s - loss: 3.7103 - output_1_loss: 2.4299 - output_2_loss: 0.0427 - output_1_Top-1 Accuracy: 0.3360 - output_1_Top-5 Accuracy: 0.7315 - val_loss: 4.0841 - val_output_1_loss: 2.9336 - val_output_2_loss: 0.0384 - val_output_1_Top-1 Accuracy: 0.2624 - val_output_1_Top-5 Accuracy: 0.6353 - lr: 1.0000e-05 - 38s/epoch - 49ms/step
Epoch 34/100

Epoch 34: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.
782/782 - 38s - loss: 3.7110 - output_1_loss: 2.4282 - output_2_loss: 0.0428 - output_1_Top-1 Accuracy: 0.3365 - output_1_Top-5 Accuracy: 0.7327 - val_loss: 4.0815 - val_output_1_loss: 2.9317 - val_output_2_loss: 0.0383 - val_output_1_Top-1 Accuracy: 0.2634 - val_output_1_Top-5 Accuracy: 0.6348 - lr: 1.0000e-05 - 38s/epoch - 49ms/step
Epoch 35/100
782/782 - 38s - loss: 3.7113 - output_1_loss: 2.4283 - output_2_loss: 0.0428 - output_1_Top-1 Accuracy: 0.3364 - output_1_Top-5 Accuracy: 0.7315 - val_loss: 4.0811 - val_output_1_loss: 2.9309 - val_output_2_loss: 0.0383 - val_output_1_Top-1 Accuracy: 0.2635 - val_output_1_Top-5 Accuracy: 0.6344 - lr: 1.0000e-06 - 38s/epoch - 49ms/step
Epoch 36/100
782/782 - 38s - loss: 3.7131 - output_1_loss: 2.4317 - output_2_loss: 0.0427 - output_1_Top-1 Accuracy: 0.3331 - output_1_Top-5 Accuracy: 0.7324 - val_loss: 4.0822 - val_output_1_loss: 2.9316 - val_output_2_loss: 0.0384 - val_output_1_Top-1 Accuracy: 0.2639 - val_output_1_Top-5 Accuracy: 0.6346 - lr: 1.0000e-06 - 38s/epoch - 49ms/step
Epoch 37/100

Epoch 37: ReduceLROnPlateau reducing learning rate to 1e-07.
782/782 - 39s - loss: 3.7116 - output_1_loss: 2.4296 - output_2_loss: 0.0427 - output_1_Top-1 Accuracy: 0.3366 - output_1_Top-5 Accuracy: 0.7315 - val_loss: 4.0825 - val_output_1_loss: 2.9326 - val_output_2_loss: 0.0383 - val_output_1_Top-1 Accuracy: 0.2619 - val_output_1_Top-5 Accuracy: 0.6337 - lr: 1.0000e-06 - 39s/epoch - 49ms/step
Epoch 38/100
782/782 - 38s - loss: 3.7117 - output_1_loss: 2.4290 - output_2_loss: 0.0428 - output_1_Top-1 Accuracy: 0.3356 - output_1_Top-5 Accuracy: 0.7319 - val_loss: 4.0800 - val_output_1_loss: 2.9296 - val_output_2_loss: 0.0383 - val_output_1_Top-1 Accuracy: 0.2625 - val_output_1_Top-5 Accuracy: 0.6348 - lr: 1.0000e-07 - 38s/epoch - 49ms/step
Epoch 38: early stopping
<keras.src.engine.input_layer.InputLayer object at 0x7f1c8a69f1f0>
<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7f1ca830cca0>
<keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x7f1ca830d150>
<keras.src.layers.core.activation.Activation object at 0x7f1ca830fb50>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca830c310>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85c47c70>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c884c7550>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c88b10dc0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c852754b0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca83aa9e0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca833e380>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85c87a90>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85cc7160>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca83a75e0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca832c700>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca83e71f0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca83bec20>
<keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7f1c85cc7eb0>
<keras.src.layers.regularization.dropout.Dropout object at 0x7f1ca83d9c00>
<keras.src.layers.core.dense.Dense object at 0x7f1ca83bf2b0>
<tempature_softmax_activation_layer.TempatureSoftmaxActivationLayer object at 0x7f1ca83da650>
<keras.src.engine.input_layer.InputLayer object at 0x7f1c8a69f1f0>
<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7f1ca830cca0>
<keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x7f1ca830d150>
<keras.src.layers.core.activation.Activation object at 0x7f1ca830fb50>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca830c310>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85c47c70>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c884c7550>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c88b10dc0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c852754b0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca83aa9e0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca833e380>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85c87a90>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85cc7160>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca83a75e0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca832c700>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca83e71f0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca83bec20>
<keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7f1c85cc7eb0>
<keras.src.layers.regularization.dropout.Dropout object at 0x7f1ca83d9c00>
<keras.src.layers.core.dense.Dense object at 0x7f1ca83bf2b0>
<tempature_softmax_activation_layer.TempatureSoftmaxActivationLayer object at 0x7f1ca83da650>
<keras.src.engine.input_layer.InputLayer object at 0x7f1c8a69f1f0>
<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7f1ca830cca0>
<keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x7f1ca830d150>
<keras.src.layers.core.activation.Activation object at 0x7f1ca830fb50>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca830c310>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85c47c70>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c884c7550>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c88b10dc0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c852754b0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca83aa9e0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca833e380>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85c87a90>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85cc7160>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca83a75e0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca832c700>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca83e71f0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca83bec20>
<keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7f1c85cc7eb0>
<keras.src.layers.regularization.dropout.Dropout object at 0x7f1ca83d9c00>
<keras.src.layers.core.dense.Dense object at 0x7f1ca83bf2b0>
<tempature_softmax_activation_layer.TempatureSoftmaxActivationLayer object at 0x7f1ca83da650>
<keras.src.engine.input_layer.InputLayer object at 0x7f1c8a69f1f0>
<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7f1ca830cca0>
<keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x7f1ca830d150>
<keras.src.layers.core.activation.Activation object at 0x7f1ca830fb50>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca830c310>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85c47c70>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c884c7550>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c88b10dc0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c852754b0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca83aa9e0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca833e380>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85c87a90>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85cc7160>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca83a75e0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca832c700>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca83e71f0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca83bec20>
<keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7f1c85cc7eb0>
<keras.src.layers.regularization.dropout.Dropout object at 0x7f1ca83d9c00>
<keras.src.layers.core.dense.Dense object at 0x7f1ca83bf2b0>
<tempature_softmax_activation_layer.TempatureSoftmaxActivationLayer object at 0x7f1ca83da650>
Model: "model_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_4 (InputLayer)        [(None, 48, 48, 3)]       0         
                                                                 
 conv2d_42 (Conv2D)          (None, 23, 23, 24)        672       
                                                                 
 batch_normalization_120 (B  (None, 23, 23, 24)        96        
 atchNormalization)                                              
                                                                 
 activation_42 (Activation)  (None, 23, 23, 24)        0         
                                                                 
 linear_bottleneck_block_39  (None, 12, 12, 24)        1368      
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_40  (None, 12, 12, 24)        1368      
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_41  (None, 12, 12, 24)        1368      
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_42  (None, 12, 12, 24)        1368      
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_43  (None, 6, 6, 96)          4464      
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_44  (None, 6, 6, 96)          12384     
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_45  (None, 6, 6, 96)          12384     
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_46  (None, 6, 6, 96)          12384     
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_47  (None, 3, 3, 168)         20664     
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_48  (None, 3, 3, 168)         33768     
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_49  (None, 3, 3, 168)         33768     
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_50  (None, 2, 2, 192)         38256     
  (LinearBottleneckBlock)                                        
                                                                 
 linear_bottleneck_block_51  (None, 2, 2, 384)         83712     
  (LinearBottleneckBlock)                                        
                                                                 
 global_average_pooling2d_3  (None, 384)               0         
  (GlobalAveragePooling2D)                                       
                                                                 
 dropout_3 (Dropout)         (None, 384)               0         
                                                                 
 output_1 (Dense)            (None, 200)               77000     
                                                                 
 output_2 (TempatureSoftmax  (None, 200)               0         
 ActivationLayer)                                                
                                                                 
=================================================================
Total params: 335024 (1.28 MB)
Trainable params: 326336 (1.24 MB)
Non-trainable params: 8688 (33.94 KB)
_________________________________________________________________
Epoch 1/100
782/782 - 47s - loss: 4.8162 - output_1_loss: 3.2739 - output_2_loss: 0.0514 - output_1_Top-1 Accuracy: 0.2209 - output_1_Top-5 Accuracy: 0.5476 - val_loss: 4.7568 - val_output_1_loss: 3.3894 - val_output_2_loss: 0.0456 - val_output_1_Top-1 Accuracy: 0.2103 - val_output_1_Top-5 Accuracy: 0.5190 - lr: 0.1000 - 47s/epoch - 60ms/step
Epoch 2/100
782/782 - 33s - loss: 4.6659 - output_1_loss: 3.1562 - output_2_loss: 0.0503 - output_1_Top-1 Accuracy: 0.2368 - output_1_Top-5 Accuracy: 0.5711 - val_loss: 5.2443 - val_output_1_loss: 3.8368 - val_output_2_loss: 0.0469 - val_output_1_Top-1 Accuracy: 0.1600 - val_output_1_Top-5 Accuracy: 0.4468 - lr: 0.1000 - 33s/epoch - 42ms/step
Epoch 3/100
782/782 - 32s - loss: 4.5987 - output_1_loss: 3.1051 - output_2_loss: 0.0498 - output_1_Top-1 Accuracy: 0.2425 - output_1_Top-5 Accuracy: 0.5845 - val_loss: 5.0757 - val_output_1_loss: 3.6803 - val_output_2_loss: 0.0465 - val_output_1_Top-1 Accuracy: 0.1733 - val_output_1_Top-5 Accuracy: 0.4620 - lr: 0.1000 - 32s/epoch - 41ms/step
Epoch 4/100

Epoch 4: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.
782/782 - 32s - loss: 4.5464 - output_1_loss: 3.0638 - output_2_loss: 0.0494 - output_1_Top-1 Accuracy: 0.2481 - output_1_Top-5 Accuracy: 0.5926 - val_loss: 4.9944 - val_output_1_loss: 3.6574 - val_output_2_loss: 0.0446 - val_output_1_Top-1 Accuracy: 0.1821 - val_output_1_Top-5 Accuracy: 0.4880 - lr: 0.1000 - 32s/epoch - 41ms/step
Epoch 5/100
782/782 - 32s - loss: 4.2840 - output_1_loss: 2.8698 - output_2_loss: 0.0471 - output_1_Top-1 Accuracy: 0.2751 - output_1_Top-5 Accuracy: 0.6341 - val_loss: 4.3378 - val_output_1_loss: 3.1098 - val_output_2_loss: 0.0409 - val_output_1_Top-1 Accuracy: 0.2476 - val_output_1_Top-5 Accuracy: 0.5941 - lr: 0.0100 - 32s/epoch - 41ms/step
Epoch 6/100
782/782 - 32s - loss: 4.1890 - output_1_loss: 2.7959 - output_2_loss: 0.0464 - output_1_Top-1 Accuracy: 0.2858 - output_1_Top-5 Accuracy: 0.6513 - val_loss: 4.2997 - val_output_1_loss: 3.0801 - val_output_2_loss: 0.0407 - val_output_1_Top-1 Accuracy: 0.2488 - val_output_1_Top-5 Accuracy: 0.5995 - lr: 0.0100 - 32s/epoch - 42ms/step
Epoch 7/100
782/782 - 32s - loss: 4.1551 - output_1_loss: 2.7735 - output_2_loss: 0.0461 - output_1_Top-1 Accuracy: 0.2872 - output_1_Top-5 Accuracy: 0.6575 - val_loss: 4.3056 - val_output_1_loss: 3.0837 - val_output_2_loss: 0.0407 - val_output_1_Top-1 Accuracy: 0.2512 - val_output_1_Top-5 Accuracy: 0.5981 - lr: 0.0100 - 32s/epoch - 41ms/step
Epoch 8/100
782/782 - 32s - loss: 4.1307 - output_1_loss: 2.7547 - output_2_loss: 0.0459 - output_1_Top-1 Accuracy: 0.2909 - output_1_Top-5 Accuracy: 0.6613 - val_loss: 4.2882 - val_output_1_loss: 3.0695 - val_output_2_loss: 0.0406 - val_output_1_Top-1 Accuracy: 0.2501 - val_output_1_Top-5 Accuracy: 0.6008 - lr: 0.0100 - 32s/epoch - 41ms/step
Epoch 9/100
782/782 - 32s - loss: 4.1078 - output_1_loss: 2.7378 - output_2_loss: 0.0457 - output_1_Top-1 Accuracy: 0.2915 - output_1_Top-5 Accuracy: 0.6643 - val_loss: 4.2946 - val_output_1_loss: 3.0794 - val_output_2_loss: 0.0405 - val_output_1_Top-1 Accuracy: 0.2527 - val_output_1_Top-5 Accuracy: 0.5998 - lr: 0.0100 - 32s/epoch - 41ms/step
Epoch 10/100
782/782 - 32s - loss: 4.0983 - output_1_loss: 2.7306 - output_2_loss: 0.0456 - output_1_Top-1 Accuracy: 0.2917 - output_1_Top-5 Accuracy: 0.6668 - val_loss: 4.2917 - val_output_1_loss: 3.0714 - val_output_2_loss: 0.0407 - val_output_1_Top-1 Accuracy: 0.2546 - val_output_1_Top-5 Accuracy: 0.5996 - lr: 0.0100 - 32s/epoch - 41ms/step
Epoch 11/100

Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.
782/782 - 32s - loss: 4.0819 - output_1_loss: 2.7196 - output_2_loss: 0.0454 - output_1_Top-1 Accuracy: 0.2937 - output_1_Top-5 Accuracy: 0.6682 - val_loss: 4.2894 - val_output_1_loss: 3.0746 - val_output_2_loss: 0.0405 - val_output_1_Top-1 Accuracy: 0.2533 - val_output_1_Top-5 Accuracy: 0.6010 - lr: 0.0100 - 32s/epoch - 41ms/step
Epoch 12/100
782/782 - 32s - loss: 4.0443 - output_1_loss: 2.6863 - output_2_loss: 0.0453 - output_1_Top-1 Accuracy: 0.2992 - output_1_Top-5 Accuracy: 0.6756 - val_loss: 4.2825 - val_output_1_loss: 3.0729 - val_output_2_loss: 0.0403 - val_output_1_Top-1 Accuracy: 0.2519 - val_output_1_Top-5 Accuracy: 0.6047 - lr: 1.0000e-03 - 32s/epoch - 41ms/step
Epoch 13/100
782/782 - 32s - loss: 4.0310 - output_1_loss: 2.6762 - output_2_loss: 0.0452 - output_1_Top-1 Accuracy: 0.3002 - output_1_Top-5 Accuracy: 0.6775 - val_loss: 4.2801 - val_output_1_loss: 3.0714 - val_output_2_loss: 0.0403 - val_output_1_Top-1 Accuracy: 0.2502 - val_output_1_Top-5 Accuracy: 0.6032 - lr: 1.0000e-03 - 32s/epoch - 41ms/step
Epoch 14/100
782/782 - 32s - loss: 4.0312 - output_1_loss: 2.6777 - output_2_loss: 0.0451 - output_1_Top-1 Accuracy: 0.2990 - output_1_Top-5 Accuracy: 0.6769 - val_loss: 4.2834 - val_output_1_loss: 3.0745 - val_output_2_loss: 0.0403 - val_output_1_Top-1 Accuracy: 0.2481 - val_output_1_Top-5 Accuracy: 0.6041 - lr: 1.0000e-03 - 32s/epoch - 41ms/step
Epoch 15/100
782/782 - 33s - loss: 4.0284 - output_1_loss: 2.6770 - output_2_loss: 0.0450 - output_1_Top-1 Accuracy: 0.2999 - output_1_Top-5 Accuracy: 0.6772 - val_loss: 4.2803 - val_output_1_loss: 3.0729 - val_output_2_loss: 0.0402 - val_output_1_Top-1 Accuracy: 0.2499 - val_output_1_Top-5 Accuracy: 0.6036 - lr: 1.0000e-03 - 33s/epoch - 42ms/step
Epoch 16/100
782/782 - 32s - loss: 4.0238 - output_1_loss: 2.6721 - output_2_loss: 0.0451 - output_1_Top-1 Accuracy: 0.3013 - output_1_Top-5 Accuracy: 0.6790 - val_loss: 4.2797 - val_output_1_loss: 3.0713 - val_output_2_loss: 0.0403 - val_output_1_Top-1 Accuracy: 0.2504 - val_output_1_Top-5 Accuracy: 0.6041 - lr: 1.0000e-03 - 32s/epoch - 41ms/step
Epoch 17/100
782/782 - 32s - loss: 4.0233 - output_1_loss: 2.6731 - output_2_loss: 0.0450 - output_1_Top-1 Accuracy: 0.3004 - output_1_Top-5 Accuracy: 0.6778 - val_loss: 4.2801 - val_output_1_loss: 3.0720 - val_output_2_loss: 0.0403 - val_output_1_Top-1 Accuracy: 0.2492 - val_output_1_Top-5 Accuracy: 0.6035 - lr: 1.0000e-03 - 32s/epoch - 41ms/step
Epoch 18/100
782/782 - 33s - loss: 4.0159 - output_1_loss: 2.6665 - output_2_loss: 0.0450 - output_1_Top-1 Accuracy: 0.3009 - output_1_Top-5 Accuracy: 0.6781 - val_loss: 4.2839 - val_output_1_loss: 3.0770 - val_output_2_loss: 0.0402 - val_output_1_Top-1 Accuracy: 0.2499 - val_output_1_Top-5 Accuracy: 0.6037 - lr: 1.0000e-03 - 33s/epoch - 42ms/step
Epoch 19/100
782/782 - 32s - loss: 4.0199 - output_1_loss: 2.6699 - output_2_loss: 0.0450 - output_1_Top-1 Accuracy: 0.2993 - output_1_Top-5 Accuracy: 0.6780 - val_loss: 4.2791 - val_output_1_loss: 3.0712 - val_output_2_loss: 0.0403 - val_output_1_Top-1 Accuracy: 0.2514 - val_output_1_Top-5 Accuracy: 0.6051 - lr: 1.0000e-03 - 32s/epoch - 41ms/step
Epoch 20/100
782/782 - 32s - loss: 4.0159 - output_1_loss: 2.6674 - output_2_loss: 0.0449 - output_1_Top-1 Accuracy: 0.2996 - output_1_Top-5 Accuracy: 0.6793 - val_loss: 4.2795 - val_output_1_loss: 3.0724 - val_output_2_loss: 0.0402 - val_output_1_Top-1 Accuracy: 0.2498 - val_output_1_Top-5 Accuracy: 0.6040 - lr: 1.0000e-03 - 32s/epoch - 41ms/step
Epoch 21/100
782/782 - 33s - loss: 4.0176 - output_1_loss: 2.6677 - output_2_loss: 0.0450 - output_1_Top-1 Accuracy: 0.2993 - output_1_Top-5 Accuracy: 0.6782 - val_loss: 4.2783 - val_output_1_loss: 3.0703 - val_output_2_loss: 0.0403 - val_output_1_Top-1 Accuracy: 0.2501 - val_output_1_Top-5 Accuracy: 0.6036 - lr: 1.0000e-03 - 33s/epoch - 42ms/step
Epoch 22/100
782/782 - 32s - loss: 4.0204 - output_1_loss: 2.6695 - output_2_loss: 0.0450 - output_1_Top-1 Accuracy: 0.2988 - output_1_Top-5 Accuracy: 0.6801 - val_loss: 4.2806 - val_output_1_loss: 3.0736 - val_output_2_loss: 0.0402 - val_output_1_Top-1 Accuracy: 0.2517 - val_output_1_Top-5 Accuracy: 0.6053 - lr: 1.0000e-03 - 32s/epoch - 41ms/step
Epoch 23/100
782/782 - 32s - loss: 4.0150 - output_1_loss: 2.6672 - output_2_loss: 0.0449 - output_1_Top-1 Accuracy: 0.3017 - output_1_Top-5 Accuracy: 0.6797 - val_loss: 4.2780 - val_output_1_loss: 3.0713 - val_output_2_loss: 0.0402 - val_output_1_Top-1 Accuracy: 0.2511 - val_output_1_Top-5 Accuracy: 0.6038 - lr: 1.0000e-03 - 32s/epoch - 41ms/step
Epoch 24/100
782/782 - 33s - loss: 4.0101 - output_1_loss: 2.6636 - output_2_loss: 0.0449 - output_1_Top-1 Accuracy: 0.2999 - output_1_Top-5 Accuracy: 0.6807 - val_loss: 4.2813 - val_output_1_loss: 3.0733 - val_output_2_loss: 0.0403 - val_output_1_Top-1 Accuracy: 0.2515 - val_output_1_Top-5 Accuracy: 0.6056 - lr: 1.0000e-03 - 33s/epoch - 42ms/step
Epoch 25/100
782/782 - 32s - loss: 4.0116 - output_1_loss: 2.6632 - output_2_loss: 0.0449 - output_1_Top-1 Accuracy: 0.3003 - output_1_Top-5 Accuracy: 0.6802 - val_loss: 4.2820 - val_output_1_loss: 3.0752 - val_output_2_loss: 0.0402 - val_output_1_Top-1 Accuracy: 0.2502 - val_output_1_Top-5 Accuracy: 0.6039 - lr: 1.0000e-03 - 32s/epoch - 41ms/step
Epoch 26/100

Epoch 26: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.
782/782 - 33s - loss: 4.0106 - output_1_loss: 2.6632 - output_2_loss: 0.0449 - output_1_Top-1 Accuracy: 0.3012 - output_1_Top-5 Accuracy: 0.6804 - val_loss: 4.2786 - val_output_1_loss: 3.0720 - val_output_2_loss: 0.0402 - val_output_1_Top-1 Accuracy: 0.2506 - val_output_1_Top-5 Accuracy: 0.6049 - lr: 1.0000e-03 - 33s/epoch - 42ms/step
Epoch 27/100
782/782 - 33s - loss: 4.0046 - output_1_loss: 2.6576 - output_2_loss: 0.0449 - output_1_Top-1 Accuracy: 0.3005 - output_1_Top-5 Accuracy: 0.6824 - val_loss: 4.2786 - val_output_1_loss: 3.0715 - val_output_2_loss: 0.0402 - val_output_1_Top-1 Accuracy: 0.2513 - val_output_1_Top-5 Accuracy: 0.6041 - lr: 1.0000e-04 - 33s/epoch - 42ms/step
Epoch 28/100
782/782 - 32s - loss: 3.9983 - output_1_loss: 2.6525 - output_2_loss: 0.0449 - output_1_Top-1 Accuracy: 0.3021 - output_1_Top-5 Accuracy: 0.6828 - val_loss: 4.2794 - val_output_1_loss: 3.0736 - val_output_2_loss: 0.0402 - val_output_1_Top-1 Accuracy: 0.2497 - val_output_1_Top-5 Accuracy: 0.6054 - lr: 1.0000e-04 - 32s/epoch - 41ms/step
Epoch 29/100

Epoch 29: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.
782/782 - 33s - loss: 4.0028 - output_1_loss: 2.6568 - output_2_loss: 0.0449 - output_1_Top-1 Accuracy: 0.3013 - output_1_Top-5 Accuracy: 0.6804 - val_loss: 4.2785 - val_output_1_loss: 3.0710 - val_output_2_loss: 0.0402 - val_output_1_Top-1 Accuracy: 0.2518 - val_output_1_Top-5 Accuracy: 0.6038 - lr: 1.0000e-04 - 33s/epoch - 43ms/step
Epoch 30/100
782/782 - 33s - loss: 3.9987 - output_1_loss: 2.6532 - output_2_loss: 0.0449 - output_1_Top-1 Accuracy: 0.3039 - output_1_Top-5 Accuracy: 0.6832 - val_loss: 4.2792 - val_output_1_loss: 3.0725 - val_output_2_loss: 0.0402 - val_output_1_Top-1 Accuracy: 0.2516 - val_output_1_Top-5 Accuracy: 0.6039 - lr: 1.0000e-05 - 33s/epoch - 42ms/step
Epoch 31/100
782/782 - 32s - loss: 4.0044 - output_1_loss: 2.6586 - output_2_loss: 0.0449 - output_1_Top-1 Accuracy: 0.3021 - output_1_Top-5 Accuracy: 0.6824 - val_loss: 4.2766 - val_output_1_loss: 3.0693 - val_output_2_loss: 0.0402 - val_output_1_Top-1 Accuracy: 0.2516 - val_output_1_Top-5 Accuracy: 0.6051 - lr: 1.0000e-05 - 32s/epoch - 41ms/step
Epoch 32/100
782/782 - 33s - loss: 3.9983 - output_1_loss: 2.6536 - output_2_loss: 0.0448 - output_1_Top-1 Accuracy: 0.3023 - output_1_Top-5 Accuracy: 0.6824 - val_loss: 4.2786 - val_output_1_loss: 3.0718 - val_output_2_loss: 0.0402 - val_output_1_Top-1 Accuracy: 0.2515 - val_output_1_Top-5 Accuracy: 0.6053 - lr: 1.0000e-05 - 33s/epoch - 43ms/step
Epoch 33/100
782/782 - 33s - loss: 4.0009 - output_1_loss: 2.6552 - output_2_loss: 0.0449 - output_1_Top-1 Accuracy: 0.3019 - output_1_Top-5 Accuracy: 0.6828 - val_loss: 4.2792 - val_output_1_loss: 3.0727 - val_output_2_loss: 0.0402 - val_output_1_Top-1 Accuracy: 0.2512 - val_output_1_Top-5 Accuracy: 0.6041 - lr: 1.0000e-05 - 33s/epoch - 42ms/step
Epoch 34/100

Epoch 34: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.
782/782 - 32s - loss: 4.0017 - output_1_loss: 2.6570 - output_2_loss: 0.0448 - output_1_Top-1 Accuracy: 0.3019 - output_1_Top-5 Accuracy: 0.6813 - val_loss: 4.2781 - val_output_1_loss: 3.0715 - val_output_2_loss: 0.0402 - val_output_1_Top-1 Accuracy: 0.2513 - val_output_1_Top-5 Accuracy: 0.6056 - lr: 1.0000e-05 - 32s/epoch - 41ms/step
Epoch 35/100
782/782 - 32s - loss: 4.0037 - output_1_loss: 2.6565 - output_2_loss: 0.0449 - output_1_Top-1 Accuracy: 0.3033 - output_1_Top-5 Accuracy: 0.6814 - val_loss: 4.2789 - val_output_1_loss: 3.0729 - val_output_2_loss: 0.0402 - val_output_1_Top-1 Accuracy: 0.2507 - val_output_1_Top-5 Accuracy: 0.6047 - lr: 1.0000e-06 - 32s/epoch - 41ms/step
Epoch 36/100
782/782 - 33s - loss: 4.0028 - output_1_loss: 2.6556 - output_2_loss: 0.0449 - output_1_Top-1 Accuracy: 0.3020 - output_1_Top-5 Accuracy: 0.6822 - val_loss: 4.2783 - val_output_1_loss: 3.0716 - val_output_2_loss: 0.0402 - val_output_1_Top-1 Accuracy: 0.2503 - val_output_1_Top-5 Accuracy: 0.6043 - lr: 1.0000e-06 - 33s/epoch - 42ms/step
Epoch 37/100

Epoch 37: ReduceLROnPlateau reducing learning rate to 1e-07.
782/782 - 33s - loss: 4.0003 - output_1_loss: 2.6535 - output_2_loss: 0.0449 - output_1_Top-1 Accuracy: 0.3041 - output_1_Top-5 Accuracy: 0.6824 - val_loss: 4.2790 - val_output_1_loss: 3.0721 - val_output_2_loss: 0.0402 - val_output_1_Top-1 Accuracy: 0.2521 - val_output_1_Top-5 Accuracy: 0.6057 - lr: 1.0000e-06 - 33s/epoch - 42ms/step
Epoch 38/100
782/782 - 32s - loss: 4.0027 - output_1_loss: 2.6579 - output_2_loss: 0.0448 - output_1_Top-1 Accuracy: 0.3025 - output_1_Top-5 Accuracy: 0.6814 - val_loss: 4.2794 - val_output_1_loss: 3.0729 - val_output_2_loss: 0.0402 - val_output_1_Top-1 Accuracy: 0.2508 - val_output_1_Top-5 Accuracy: 0.6036 - lr: 1.0000e-07 - 32s/epoch - 41ms/step
Epoch 39/100
782/782 - 33s - loss: 3.9981 - output_1_loss: 2.6527 - output_2_loss: 0.0448 - output_1_Top-1 Accuracy: 0.3040 - output_1_Top-5 Accuracy: 0.6819 - val_loss: 4.2779 - val_output_1_loss: 3.0711 - val_output_2_loss: 0.0402 - val_output_1_Top-1 Accuracy: 0.2519 - val_output_1_Top-5 Accuracy: 0.6053 - lr: 1.0000e-07 - 33s/epoch - 42ms/step
Epoch 40/100
782/782 - 32s - loss: 4.0054 - output_1_loss: 2.6601 - output_2_loss: 0.0448 - output_1_Top-1 Accuracy: 0.3027 - output_1_Top-5 Accuracy: 0.6812 - val_loss: 4.2798 - val_output_1_loss: 3.0726 - val_output_2_loss: 0.0402 - val_output_1_Top-1 Accuracy: 0.2500 - val_output_1_Top-5 Accuracy: 0.6033 - lr: 1.0000e-07 - 32s/epoch - 41ms/step
Epoch 41/100
782/782 - 32s - loss: 4.0030 - output_1_loss: 2.6564 - output_2_loss: 0.0449 - output_1_Top-1 Accuracy: 0.3018 - output_1_Top-5 Accuracy: 0.6806 - val_loss: 4.2772 - val_output_1_loss: 3.0701 - val_output_2_loss: 0.0402 - val_output_1_Top-1 Accuracy: 0.2520 - val_output_1_Top-5 Accuracy: 0.6048 - lr: 1.0000e-07 - 32s/epoch - 41ms/step
Epoch 41: early stopping
<keras.src.engine.input_layer.InputLayer object at 0x7f1c868af3a0>
<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7f1cb87c2ad0>
<keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x7f1cb87c3880>
<keras.src.layers.core.activation.Activation object at 0x7f1c81500a60>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb87c1330>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb87c1930>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85409510>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca8bd3d30>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85cf52a0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb87c87f0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca8b463b0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb8725ae0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb8705f30>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb8704970>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb8793640>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb879fe80>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca8bac4c0>
<keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7f1c86aeedd0>
<keras.src.layers.regularization.dropout.Dropout object at 0x7f1cb87ef5e0>
<keras.src.layers.core.dense.Dense object at 0x7f1cb87d5090>
<tempature_softmax_activation_layer.TempatureSoftmaxActivationLayer object at 0x7f1c856f9f30>
<keras.src.engine.input_layer.InputLayer object at 0x7f1c868af3a0>
<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7f1cb87c2ad0>
<keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x7f1cb87c3880>
<keras.src.layers.core.activation.Activation object at 0x7f1c81500a60>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb87c1330>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb87c1930>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85409510>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca8bd3d30>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85cf52a0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb87c87f0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca8b463b0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb8725ae0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb8705f30>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb8704970>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb8793640>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb879fe80>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca8bac4c0>
<keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7f1c86aeedd0>
<keras.src.layers.regularization.dropout.Dropout object at 0x7f1cb87ef5e0>
<keras.src.layers.core.dense.Dense object at 0x7f1cb87d5090>
<tempature_softmax_activation_layer.TempatureSoftmaxActivationLayer object at 0x7f1c856f9f30>
<keras.src.engine.input_layer.InputLayer object at 0x7f1c868af3a0>
<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7f1cb87c2ad0>
<keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x7f1cb87c3880>
<keras.src.layers.core.activation.Activation object at 0x7f1c81500a60>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb87c1330>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb87c1930>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85409510>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca8bd3d30>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85cf52a0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb87c87f0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca8b463b0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb8725ae0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb8705f30>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb8704970>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb8793640>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb879fe80>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca8bac4c0>
<keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7f1c86aeedd0>
<keras.src.layers.regularization.dropout.Dropout object at 0x7f1cb87ef5e0>
<keras.src.layers.core.dense.Dense object at 0x7f1cb87d5090>
<tempature_softmax_activation_layer.TempatureSoftmaxActivationLayer object at 0x7f1c856f9f30>
<keras.src.engine.input_layer.InputLayer object at 0x7f1c868af3a0>
<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7f1cb87c2ad0>
<keras.src.layers.normalization.batch_normalization.BatchNormalization object at 0x7f1cb87c3880>
<keras.src.layers.core.activation.Activation object at 0x7f1c81500a60>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb87c1330>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb87c1930>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85409510>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca8bd3d30>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1c85cf52a0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb87c87f0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca8b463b0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb8725ae0>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb8705f30>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb8704970>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb8793640>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1cb879fe80>
<etinynet_blocks.LinearBottleneckBlock object at 0x7f1ca8bac4c0>
<keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7f1c86aeedd0>
<keras.src.layers.regularization.dropout.Dropout object at 0x7f1cb87ef5e0>
<keras.src.layers.core.dense.Dense object at 0x7f1cb87d5090>
<tempature_softmax_activation_layer.TempatureSoftmaxActivationLayer object at 0x7f1c856f9f30>
